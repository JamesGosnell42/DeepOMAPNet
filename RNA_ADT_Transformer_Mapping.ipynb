{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a2c6132",
   "metadata": {},
   "source": [
    "# Transformer Mapping between GAT Embeddings of RNA and ADT\n",
    "\n",
    "This notebook learns a mapping between GAT embeddings from RNA data and GAT embeddings from ADT data using a Transformer Encoder architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde7f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory optimization and system check\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Set memory management environment variables\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# Check system resources\n",
    "print(\"=== System Resources ===\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    gpu_props = torch.cuda.get_device_properties(device)\n",
    "    total_memory = gpu_props.total_memory / (1024**3)  # Convert to GB\n",
    "    \n",
    "    print(f\"GPU: {gpu_props.name}\")\n",
    "    print(f\"Total GPU Memory: {total_memory:.1f} GB\")\n",
    "    print(f\"GPU Compute Capability: {gpu_props.major}.{gpu_props.minor}\")\n",
    "    \n",
    "    # Clear any cached memory\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Check current memory usage\n",
    "    allocated = torch.cuda.memory_allocated(device) / (1024**3)\n",
    "    reserved = torch.cuda.memory_reserved(device) / (1024**3)\n",
    "    \n",
    "    print(f\"Currently allocated: {allocated:.2f} GB\")\n",
    "    print(f\"Currently reserved: {reserved:.2f} GB\")\n",
    "    print(f\"Available: {total_memory - reserved:.2f} GB\")\n",
    "    \n",
    "    # Set recommendations based on available memory\n",
    "    if total_memory < 8:\n",
    "        print(\"\\n⚠️  WARNING: Low GPU memory detected!\")\n",
    "        print(\"Recommendations:\")\n",
    "        print(\"- Use CPU fallback if needed\")\n",
    "        print(\"- Reduce batch sizes\")\n",
    "        print(\"- Use graph sparsification\")\n",
    "    elif total_memory < 16:\n",
    "        print(\"\\n💡 Moderate GPU memory - will use optimized settings\")\n",
    "    else:\n",
    "        print(\"\\n✅ Sufficient GPU memory available\")\n",
    "        \n",
    "else:\n",
    "    print(\"CUDA not available - will use CPU\")\n",
    "    print(\"Note: Training will be slower but should work with larger graphs\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24112ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set environment variables for better memory management\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import pandas as pd\n",
    "\n",
    "import scanpy as sc\n",
    "import scanpy.external as sce\n",
    "from scipy import sparse\n",
    "\n",
    "from DeepOMAPNet.Preprocess import prepare_train_test_anndata\n",
    "\n",
    "# Set memory management\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB\")\n",
    "else:\n",
    "    print(\"CUDA not available, using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c2a7a",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b709d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "data = prepare_train_test_anndata()\n",
    "trainGene = data[0]  # RNA data\n",
    "trainADT = data[2]   # ADT data\n",
    "\n",
    "print(f\"RNA data shape: {trainGene.shape}\")\n",
    "print(f\"ADT data shape: {trainADT.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e234eb83",
   "metadata": {},
   "source": [
    "## 2. Preprocess RNA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f546328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNA preprocessing\n",
    "sc.pp.normalize_total(trainGene, target_sum=1e4)\n",
    "sc.pp.log1p(trainGene)\n",
    "sc.pp.highly_variable_genes(trainGene, n_top_genes=2000, batch_key=\"samples\")\n",
    "trainGene = trainGene[:, trainGene.var.highly_variable].copy()\n",
    "\n",
    "sc.pp.scale(trainGene, max_value=10)\n",
    "sc.tl.pca(trainGene, n_comps=50, svd_solver=\"arpack\")\n",
    "\n",
    "# Build neighbor graph for RNA\n",
    "sc.pp.neighbors(trainGene, n_neighbors=15, n_pcs=50)\n",
    "sc.tl.leiden(trainGene, resolution=1.0)\n",
    "\n",
    "print(f\"RNA data after preprocessing: {trainGene.shape}\")\n",
    "print(f\"Number of RNA clusters: {trainGene.obs['leiden'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb07a02",
   "metadata": {},
   "source": [
    "## 3. Preprocess ADT Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df180c9",
   "metadata": {},
   "source": [
    "## 3. Centered Log-Ratio (CLR) Normalization for ADT Data\n",
    "\n",
    "Before we apply standard preprocessing steps, we'll perform Centered Log-Ratio (CLR) normalization on the ADT data. CLR normalization is particularly suited for ADT/CITE-seq data because:\n",
    "\n",
    "1. It handles the compositional nature of the data\n",
    "2. It preserves relative differences between markers\n",
    "3. It reduces technical noise while maintaining biological signal\n",
    "\n",
    "The CLR transformation is defined as:\n",
    "\n",
    "$$\\text{CLR}(x) = \\log(x) - \\frac{1}{D}\\sum_{i=1}^{D}\\log(x_i)$$\n",
    "\n",
    "Where $D$ is the number of features (ADT markers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68aa845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def clr_normalize(adata, axis=1, pseudo_count=1):\n",
    "    \"\"\"\n",
    "    Apply centered log-ratio normalization to the data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : AnnData\n",
    "        AnnData object with raw counts\n",
    "    axis : int, default=1\n",
    "        0 = normalize features (columns), 1 = normalize cells (rows)\n",
    "    pseudo_count : float, default=1\n",
    "        Value to add to counts before log transform to avoid log(0)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    AnnData with CLR-normalized values in .X\n",
    "    \"\"\"\n",
    "    print(\"Applying CLR normalization to ADT data...\")\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    adata_clr = adata.copy()\n",
    "    \n",
    "    # Get raw counts (densify if sparse)\n",
    "    X = adata_clr.X.toarray() if scipy.sparse.issparse(adata_clr.X) else adata_clr.X.copy()\n",
    "    \n",
    "    # Add pseudo count\n",
    "    X += pseudo_count\n",
    "    \n",
    "    # Calculate geometric mean of each cell (row) or feature (column)\n",
    "    if axis == 1:  # across features (for each cell)\n",
    "        # Get geometric mean for each cell\n",
    "        geometric_means = np.exp(np.mean(np.log(X), axis=1, keepdims=True))\n",
    "        # CLR transformation\n",
    "        X_clr = np.log(X / geometric_means)\n",
    "    else:  # across cells (for each feature)\n",
    "        # Get geometric mean for each feature\n",
    "        geometric_means = np.exp(np.mean(np.log(X), axis=0, keepdims=True))\n",
    "        # CLR transformation\n",
    "        X_clr = np.log(X / geometric_means)\n",
    "    \n",
    "    # Update data\n",
    "    adata_clr.X = X_clr\n",
    "    \n",
    "    # Store original data in raw slot\n",
    "    adata_clr.raw = adata\n",
    "    \n",
    "    print(f\"CLR normalization complete. Shape: {adata_clr.X.shape}\")\n",
    "    return adata_clr\n",
    "\n",
    "# Apply CLR normalization to ADT data\n",
    "trainADT_clr = clr_normalize(trainADT)\n",
    "\n",
    "# Basic quality check - visualize distribution before and after normalization\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Original data distribution\n",
    "if scipy.sparse.issparse(trainADT.X):\n",
    "    sample_values = trainADT.X.data[:10000] if len(trainADT.X.data) > 10000 else trainADT.X.data\n",
    "else:\n",
    "    sample_values = trainADT.X.flatten()[:10000]\n",
    "    \n",
    "sns.histplot(sample_values, bins=50, kde=True, ax=ax[0])\n",
    "ax[0].set_title(\"Original ADT Values\")\n",
    "ax[0].set_xlabel(\"Value\")\n",
    "\n",
    "# CLR-normalized data distribution\n",
    "sample_values_clr = trainADT_clr.X.flatten()[:10000]\n",
    "sns.histplot(sample_values_clr, bins=50, kde=True, ax=ax[1])\n",
    "ax[1].set_title(\"CLR-Normalized ADT Values\")\n",
    "ax[1].set_xlabel(\"Value\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Replace original ADT data with CLR-normalized data for further processing\n",
    "trainADT = trainADT_clr\n",
    "\n",
    "print(\"ADT data now uses CLR normalization\")\n",
    "print(f\"ADT data shape: {trainADT.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60446102",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Additional ADT Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32721f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional preprocessing for ADT data\n",
    "print(\"Computing PCA and neighbor graph for ADT data...\")\n",
    "\n",
    "# Check if PCA has been computed already\n",
    "if 'X_pca' not in trainADT.obsm:\n",
    "    print(\"Computing PCA for ADT data...\")\n",
    "    sc.tl.pca(trainADT, n_comps=50, svd_solver=\"arpack\")\n",
    "\n",
    "# Compute neighbors for ADT data\n",
    "print(\"Computing neighbor graph for ADT data...\")\n",
    "sc.pp.neighbors(trainADT, n_neighbors=15, n_pcs=50)\n",
    "\n",
    "# Run leiden clustering if not already run\n",
    "if 'leiden' not in trainADT.obs:\n",
    "    print(\"Running leiden clustering on ADT data...\")\n",
    "    sc.tl.leiden(trainADT, resolution=1.0)\n",
    "\n",
    "# Verify neighbor graph was computed successfully\n",
    "if 'connectivities' in trainADT.obsp:\n",
    "    print(f\"Neighbor graph computed successfully\")\n",
    "    print(f\"Graph size: {trainADT.shape[0]} nodes, {trainADT.obsp['connectivities'].nnz} edges\")\n",
    "    print(f\"Average degree: {trainADT.obsp['connectivities'].nnz / trainADT.shape[0]:.1f}\")\n",
    "else:\n",
    "    print(\"ERROR: Failed to compute neighbor graph\")\n",
    "\n",
    "# You can also run UMAP for visualization\n",
    "if 'X_umap' not in trainADT.obsm:\n",
    "    print(\"Computing UMAP embedding for ADT data...\")\n",
    "    sc.tl.umap(trainADT)\n",
    "    \n",
    "print(\"ADT preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47920cdd",
   "metadata": {},
   "source": [
    "## 5. Build PyTorch Geometric Data Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca6654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsify_graph(adata, max_edges_per_node=50):\n",
    "    \"\"\"Sparsify the graph by keeping only top k neighbors per node\"\"\"\n",
    "    \n",
    "    # Check if connectivities exists\n",
    "    if \"connectivities\" not in adata.obsp:\n",
    "        print(\"No connectivity graph found. Computing neighbors first...\")\n",
    "        sc.pp.neighbors(adata, n_neighbors=15, n_pcs=50)\n",
    "    \n",
    "    A = adata.obsp[\"connectivities\"].tocsr()\n",
    "    n_nodes = A.shape[0]\n",
    "    \n",
    "    # Check if sparsification is needed\n",
    "    avg_degree = A.nnz / n_nodes\n",
    "    if avg_degree <= max_edges_per_node:\n",
    "        print(f\"Graph already sparse enough (avg degree: {avg_degree:.1f})\")\n",
    "        return adata\n",
    "    \n",
    "    print(f\"Sparsifying graph from avg degree {avg_degree:.1f} to max {max_edges_per_node}\")\n",
    "    \n",
    "    # Create new sparse matrix\n",
    "    row_indices = []\n",
    "    col_indices = []\n",
    "    data_values = []\n",
    "    \n",
    "    for i in range(n_nodes):\n",
    "        # Get neighbors and their weights for node i\n",
    "        start_idx = A.indptr[i]\n",
    "        end_idx = A.indptr[i + 1]\n",
    "        neighbors = A.indices[start_idx:end_idx]\n",
    "        weights = A.data[start_idx:end_idx]\n",
    "        \n",
    "        # Keep only top k neighbors\n",
    "        if len(neighbors) > max_edges_per_node:\n",
    "            top_k_indices = np.argpartition(weights, -max_edges_per_node)[-max_edges_per_node:]\n",
    "            neighbors = neighbors[top_k_indices]\n",
    "            weights = weights[top_k_indices]\n",
    "        \n",
    "        # Add edges\n",
    "        row_indices.extend([i] * len(neighbors))\n",
    "        col_indices.extend(neighbors)\n",
    "        data_values.extend(weights)\n",
    "    \n",
    "    # Create new adjacency matrix\n",
    "    A_sparse = sparse.csr_matrix(\n",
    "        (data_values, (row_indices, col_indices)), \n",
    "        shape=(n_nodes, n_nodes)\n",
    "    )\n",
    "    \n",
    "    # Make symmetric\n",
    "    A_sparse = (A_sparse + A_sparse.T) / 2\n",
    "    \n",
    "    # Update the AnnData object\n",
    "    adata.obsp[\"connectivities\"] = A_sparse\n",
    "    \n",
    "    new_avg_degree = A_sparse.nnz / n_nodes\n",
    "    print(f\"New average degree: {new_avg_degree:.1f}\")\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def build_pyg_data(adata, use_pca=True, sparsify_large_graphs=True, max_edges_per_node=50):\n",
    "    \"\"\"Build PyTorch Geometric Data object from AnnData\"\"\"\n",
    "    \n",
    "    # Ensure PCA and neighbor graph are computed\n",
    "    if use_pca and \"X_pca\" not in adata.obsm:\n",
    "        print(\"Computing PCA first...\")\n",
    "        sc.tl.pca(adata, n_comps=50, svd_solver=\"arpack\")\n",
    "    \n",
    "    if \"connectivities\" not in adata.obsp:\n",
    "        print(\"Computing neighbor graph first...\")\n",
    "        sc.pp.neighbors(adata, n_neighbors=15, n_pcs=50 if use_pca else None)\n",
    "    \n",
    "    # Sparsify if needed\n",
    "    if sparsify_large_graphs:\n",
    "        A = adata.obsp[\"connectivities\"]\n",
    "        avg_degree = A.nnz / A.shape[0]\n",
    "        if avg_degree > max_edges_per_node:\n",
    "            print(f\"Large graph detected (avg degree: {avg_degree:.1f}), applying sparsification...\")\n",
    "            adata = sparsify_graph(adata, max_edges_per_node)\n",
    "    \n",
    "    # Features\n",
    "    if use_pca:\n",
    "        X = adata.obsm[\"X_pca\"]\n",
    "    else:\n",
    "        X = adata.X.toarray() if scipy.sparse.issparse(adata.X) else adata.X.copy()\n",
    "    \n",
    "    # Labels (leiden clusters)\n",
    "    if \"leiden\" not in adata.obs:\n",
    "        print(\"Computing leiden clusters first...\")\n",
    "        sc.tl.leiden(adata, resolution=1.0)\n",
    "    \n",
    "    y = adata.obs[\"leiden\"].astype(int).to_numpy()\n",
    "    \n",
    "    # Edge index from connectivities\n",
    "    A = adata.obsp[\"connectivities\"].tocsr()\n",
    "    A_triu = sparse.triu(A, k=1)\n",
    "    row, col = A_triu.nonzero()\n",
    "    edge_index = torch.tensor(np.vstack([row, col]), dtype=torch.long)\n",
    "    \n",
    "    # Create PyG Data object\n",
    "    data = Data(\n",
    "        x=torch.tensor(X, dtype=torch.float32),\n",
    "        edge_index=edge_index,\n",
    "        y=torch.tensor(y, dtype=torch.long),\n",
    "    )\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Build data objects with memory optimization\n",
    "print(\"Building PyG data objects...\")\n",
    "\n",
    "# Check available GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB\n",
    "    print(f\"Available GPU memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Ensure neighbors are computed first for both datasets\n",
    "    if \"connectivities\" not in trainGene.obsp:\n",
    "        print(\"Computing neighbors for RNA data...\")\n",
    "        sc.pp.neighbors(trainGene, n_neighbors=15, n_pcs=50)\n",
    "        \n",
    "    if \"connectivities\" not in trainADT.obsp:\n",
    "        print(\"Computing neighbors for ADT data...\")\n",
    "        sc.pp.neighbors(trainADT, n_neighbors=15, n_pcs=50)\n",
    "    \n",
    "    # Estimate memory requirements\n",
    "    rna_edges = trainGene.obsp[\"connectivities\"].nnz\n",
    "    adt_edges = trainADT.obsp[\"connectivities\"].nnz\n",
    "    \n",
    "    print(f\"RNA graph edges: {rna_edges:,}\")\n",
    "    print(f\"ADT graph edges: {adt_edges:,}\")\n",
    "    \n",
    "    # Set sparsification based on graph size\n",
    "    max_edges_rna = 100 if rna_edges > 5000000 else 200\n",
    "    max_edges_adt = 50 if adt_edges > 10000000 else 100\n",
    "    \n",
    "    print(f\"Using max edges per node - RNA: {max_edges_rna}, ADT: {max_edges_adt}\")\n",
    "else:\n",
    "    print(\"Using CPU - no memory constraints\")\n",
    "    max_edges_rna = 200\n",
    "    max_edges_adt = 100\n",
    "\n",
    "# Build data objects\n",
    "rna_data = build_pyg_data(trainGene, use_pca=True, sparsify_large_graphs=True, max_edges_per_node=max_edges_rna)\n",
    "adt_data = build_pyg_data(trainADT, use_pca=True, sparsify_large_graphs=True, max_edges_per_node=max_edges_adt)\n",
    "\n",
    "print(f\"RNA PyG data - Nodes: {rna_data.num_nodes}, Edges: {rna_data.num_edges}, Features: {rna_data.num_node_features}\")\n",
    "print(f\"ADT PyG data - Nodes: {adt_data.num_nodes}, Edges: {adt_data.num_edges}, Features: {adt_data.num_node_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43647fa",
   "metadata": {},
   "source": [
    "## 6. Define GAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGAT(torch.nn.Module):\n",
    "    \"\"\"Simplified GAT for memory-constrained scenarios\"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=4, dropout=0.6):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Single GAT layer for memory efficiency\n",
    "        self.conv1 = GATConv(in_channels, out_channels, heads=heads, dropout=dropout, concat=False)\n",
    "        \n",
    "    def forward(self, x, edge_index, return_embeddings=False):\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        \n",
    "        if return_embeddings:\n",
    "            return x\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def get_embeddings(self, x, edge_index):\n",
    "        \"\"\"Get embeddings for mapping\"\"\"\n",
    "        return self.forward(x, edge_index, return_embeddings=True)\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=8, dropout=0.6):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, dropout=dropout)\n",
    "        \n",
    "    def forward(self, x, edge_index, return_embeddings=False):\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        if return_embeddings:\n",
    "            return x  # Return embeddings before final layer\n",
    "            \n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "    def get_embeddings(self, x, edge_index):\n",
    "        \"\"\"Get intermediate embeddings for mapping\"\"\"\n",
    "        return self.forward(x, edge_index, return_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe2098d",
   "metadata": {},
   "source": [
    "## 7. Train GAT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd0f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gat_model(data, model_name=\"GAT\", epochs=200, use_cpu_fallback=False):\n",
    "    \"\"\"Train a GAT model and return the trained model\"\"\"\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() and not use_cpu_fallback else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Check memory requirements and adjust accordingly\n",
    "    num_edges = data.num_edges\n",
    "    num_nodes = data.num_nodes\n",
    "    \n",
    "    print(f\"Graph stats - Nodes: {num_nodes}, Edges: {num_edges}\")\n",
    "    \n",
    "    # Memory optimization: reduce model size if too many edges\n",
    "    use_simple_model = False\n",
    "    if num_edges > 2000000:  # If more than 2M edges\n",
    "        print(\"Very large graph detected, using simplified GAT architecture...\")\n",
    "        hidden_dim = 32\n",
    "        heads = 4\n",
    "        use_simple_model = True\n",
    "    elif num_edges > 1000000:  # If more than 1M edges\n",
    "        print(\"Large graph detected, reducing model complexity...\")\n",
    "        hidden_dim = 32\n",
    "        heads = 4\n",
    "    else:\n",
    "        hidden_dim = 64\n",
    "        heads = 8\n",
    "    \n",
    "    # Create train/val/test masks\n",
    "    N = data.num_nodes\n",
    "    y_np = data.y.cpu().numpy()\n",
    "    \n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    \n",
    "    # Split 80/10/10\n",
    "    sss1 = StratifiedShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "    train_idx, temp_idx = next(sss1.split(np.zeros(N), y_np))\n",
    "    \n",
    "    y_temp = y_np[temp_idx]\n",
    "    sss2 = StratifiedShuffleSplit(n_splits=1, train_size=0.5, random_state=43)\n",
    "    val_rel, test_rel = next(sss2.split(np.zeros(len(temp_idx)), y_temp))\n",
    "    val_idx = temp_idx[val_rel]\n",
    "    test_idx = temp_idx[test_rel]\n",
    "    \n",
    "    train_mask = torch.zeros(N, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(N, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(N, dtype=torch.bool)\n",
    "    train_mask[train_idx] = True\n",
    "    val_mask[val_idx] = True\n",
    "    test_mask[test_idx] = True\n",
    "    \n",
    "    data.train_mask = train_mask\n",
    "    data.val_mask = val_mask\n",
    "    data.test_mask = test_mask\n",
    "    \n",
    "    # Initialize model\n",
    "    in_dim = data.x.size(1)\n",
    "    n_class = int(data.y.max().item() + 1)\n",
    "    \n",
    "    if use_simple_model:\n",
    "        model = SimpleGAT(in_dim, hidden_dim, n_class, heads=heads).to(device)\n",
    "        print(f\"Using SimpleGAT: {in_dim} -> {n_class} (hidden: {hidden_dim}, heads: {heads})\")\n",
    "    else:\n",
    "        model = GAT(in_dim, hidden_dim, n_class, heads=heads).to(device)\n",
    "        print(f\"Using GAT: {in_dim} -> {hidden_dim} -> {n_class} (heads: {heads})\")\n",
    "    \n",
    "    # Move data to device with memory management\n",
    "    cpu_fallback_triggered = False\n",
    "    try:\n",
    "        data = data.to(device)\n",
    "        print(f\"Successfully moved data to {device}\")\n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e).lower():\n",
    "            print(f\"GPU memory insufficient, falling back to CPU...\")\n",
    "            device = torch.device('cpu')\n",
    "            model = model.cpu()\n",
    "            data = data.cpu()\n",
    "            cpu_fallback_triggered = True\n",
    "        else:\n",
    "            raise e\n",
    "    \n",
    "    # Initialize optimizer and criterion\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    def train():\n",
    "        nonlocal model, data, optimizer, device, cpu_fallback_triggered\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        try:\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.empty_cache()  # Clear cache before forward pass\n",
    "            \n",
    "            out = model(data.x, data.edge_index)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.empty_cache()  # Clear cache after backward pass\n",
    "                \n",
    "            return loss\n",
    "            \n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e).lower() and not cpu_fallback_triggered:\n",
    "                print(f\"GPU OOM during training, switching to CPU...\")\n",
    "                # Move everything to CPU\n",
    "                device = torch.device('cpu')\n",
    "                model = model.cpu()\n",
    "                data = data.cpu()\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "                cpu_fallback_triggered = True\n",
    "                \n",
    "                # Retry the forward pass on CPU\n",
    "                optimizer.zero_grad()\n",
    "                out = model(data.x, data.edge_index)\n",
    "                loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                return loss\n",
    "            else:\n",
    "                raise e\n",
    "    \n",
    "    def test(mask):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            out = model(data.x, data.edge_index)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct = pred[mask] == data.y[mask]\n",
    "            acc = int(correct.sum()) / int(mask.sum())\n",
    "            return acc\n",
    "    \n",
    "    print(f\"Training {model_name} model...\")\n",
    "    best_val_acc = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        loss = train()\n",
    "        \n",
    "        if epoch % 50 == 0 or epoch == 1:\n",
    "            val_acc = test(data.val_mask)\n",
    "            test_acc = test(data.test_mask)\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_model_state = model.state_dict().copy()\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    final_test_acc = test(data.test_mask)\n",
    "    print(f\"Final {model_name} test accuracy: {final_test_acc:.4f}\")\n",
    "    \n",
    "    return model, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f51e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GAT models for both RNA and ADT with memory management\n",
    "print(\"=== Training RNA GAT ===\")\n",
    "try:\n",
    "    rna_gat_model, rna_data_with_masks = train_gat_model(rna_data, \"RNA GAT\", epochs=200)\n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e).lower():\n",
    "        print(\"GPU memory insufficient for RNA GAT, trying CPU...\")\n",
    "        rna_gat_model, rna_data_with_masks = train_gat_model(rna_data, \"RNA GAT\", epochs=200, use_cpu_fallback=True)\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "print(\"\\n=== Training ADT GAT ===\")\n",
    "try:\n",
    "    adt_gat_model, adt_data_with_masks = train_gat_model(adt_data, \"ADT GAT\", epochs=200)\n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e).lower():\n",
    "        print(\"GPU memory insufficient for ADT GAT, trying CPU...\")\n",
    "        adt_gat_model, adt_data_with_masks = train_gat_model(adt_data, \"ADT GAT\", epochs=200, use_cpu_fallback=True)\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "print(\"\\n=== GAT Training Complete ===\")\n",
    "print(f\"RNA GAT model trained successfully\")\n",
    "print(f\"ADT GAT model trained successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a896646",
   "metadata": {},
   "source": [
    "## 8. Extract GAT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5c8cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, data):\n",
    "    \"\"\"Extract embeddings from trained GAT model\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Ensure model and data are on the same device\n",
    "    device = next(model.parameters()).device\n",
    "    if data.x.device != device:\n",
    "        print(f\"Moving data from {data.x.device} to {device}\")\n",
    "        data = data.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Clear cache if using GPU\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        embeddings = model.get_embeddings(data.x, data.edge_index)\n",
    "        \n",
    "        # Move to CPU for further processing\n",
    "        embeddings = embeddings.cpu()\n",
    "        \n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    return embeddings\n",
    "\n",
    "# Clear any existing cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Extract embeddings\n",
    "print(\"Extracting embeddings...\")\n",
    "rna_embeddings = extract_embeddings(rna_gat_model, rna_data_with_masks)\n",
    "adt_embeddings = extract_embeddings(adt_gat_model, adt_data_with_masks)\n",
    "\n",
    "print(f\"RNA embeddings shape: {rna_embeddings.shape}\")\n",
    "print(f\"ADT embeddings shape: {adt_embeddings.shape}\")\n",
    "\n",
    "# Ensure both embeddings have the same number of cells\n",
    "assert rna_embeddings.shape[0] == adt_embeddings.shape[0], \"Number of cells must match\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1635b84",
   "metadata": {},
   "source": [
    "## 9. Define Transformer Encoder Mapping Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247dc1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional encoding for transformer models\"\"\"\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerMapping(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, d_model=256, nhead=4, num_layers=3, dropout=0.1):\n",
    "        super(TransformerMapping, self).__init__()\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=d_model*4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_proj = nn.Linear(d_model, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Project input to transformer dimensions\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        # Add batch dimension if not present\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(1)  # [batch_size, 1, d_model]\n",
    "            \n",
    "        # Pass through transformer encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        # Project to output dimensions\n",
    "        x = self.output_proj(x.squeeze(1))\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize transformer mapping model\n",
    "import math  # For the positional encoding\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_dim = rna_embeddings.shape[1]\n",
    "output_dim = adt_embeddings.shape[1]\n",
    "\n",
    "transformer_model = TransformerMapping(\n",
    "    input_dim=input_dim, \n",
    "    output_dim=output_dim, \n",
    "    d_model=256,\n",
    "    nhead=4,\n",
    "    num_layers=3\n",
    ").to(device)\n",
    "\n",
    "print(f\"Transformer Model: {input_dim} -> {output_dim}\")\n",
    "print(transformer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f2856",
   "metadata": {},
   "source": [
    "## 9. Prepare Training Data for Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee30a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embeddings to CPU and numpy\n",
    "rna_emb_np = rna_embeddings.cpu().numpy()\n",
    "adt_emb_np = adt_embeddings.cpu().numpy()\n",
    "\n",
    "# Split data for training (use same train/val/test split as GAT)\n",
    "train_mask_np = rna_data_with_masks.train_mask.cpu().numpy()\n",
    "val_mask_np = rna_data_with_masks.val_mask.cpu().numpy()\n",
    "test_mask_np = rna_data_with_masks.test_mask.cpu().numpy()\n",
    "\n",
    "# Prepare training data\n",
    "X_train = torch.tensor(rna_emb_np[train_mask_np], dtype=torch.float32)\n",
    "y_train = torch.tensor(adt_emb_np[train_mask_np], dtype=torch.float32)\n",
    "\n",
    "X_val = torch.tensor(rna_emb_np[val_mask_np], dtype=torch.float32)\n",
    "y_val = torch.tensor(adt_emb_np[val_mask_np], dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(rna_emb_np[test_mask_np], dtype=torch.float32)\n",
    "y_test = torch.tensor(adt_emb_np[test_mask_np], dtype=torch.float32)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64  # Smaller batch size for transformer\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95d0c8",
   "metadata": {},
   "source": [
    "## 10. Train Transformer Mapping Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_epochs = 300\n",
    "learning_rate = 0.0005  # Lower learning rate for transformer\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# Warmup scheduler\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "def get_lr_scheduler(optimizer, warmup_steps=1000, max_steps=10000):\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return float(current_step) / float(max(1, warmup_steps))\n",
    "        return max(\n",
    "            0.0, float(max_steps - current_step) / float(max(1, max_steps - warmup_steps))\n",
    "        )\n",
    "    return LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(transformer_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "patience = 30\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"Training Transformer mapping model...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    transformer_model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = transformer_model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(transformer_model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    transformer_model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = transformer_model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = transformer_model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if (epoch + 1) % 25 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}')\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f'Early stopping at epoch {epoch+1}')\n",
    "        break\n",
    "\n",
    "# Load best model\n",
    "transformer_model.load_state_dict(best_model_state)\n",
    "print(f'Best validation loss: {best_val_loss:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f004149a",
   "metadata": {},
   "source": [
    "## 11. Evaluate Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ceb5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "transformer_model.eval()\n",
    "test_loss = 0.0\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        outputs = transformer_model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        predictions.append(outputs.cpu().numpy())\n",
    "        ground_truth.append(batch_y.cpu().numpy())\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "predictions = np.vstack(predictions)\n",
    "ground_truth = np.vstack(ground_truth)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(ground_truth, predictions)\n",
    "r2 = r2_score(ground_truth, predictions)\n",
    "\n",
    "# Calculate correlation per dimension\n",
    "pearson_corrs = []\n",
    "spearman_corrs = []\n",
    "\n",
    "for i in range(ground_truth.shape[1]):\n",
    "    pearson_r, _ = pearsonr(ground_truth[:, i], predictions[:, i])\n",
    "    spearman_r, _ = spearmanr(ground_truth[:, i], predictions[:, i])\n",
    "    pearson_corrs.append(pearson_r)\n",
    "    spearman_corrs.append(spearman_r)\n",
    "\n",
    "mean_pearson = np.mean(pearson_corrs)\n",
    "mean_spearman = np.mean(spearman_corrs)\n",
    "\n",
    "print(f\"\\n=== Transformer Mapping Results ===\")\n",
    "print(f\"Test Loss (MSE): {test_loss:.6f}\")\n",
    "print(f\"MSE: {mse:.6f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"Mean Pearson Correlation: {mean_pearson:.4f}\")\n",
    "print(f\"Mean Spearman Correlation: {mean_spearman:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f89e08",
   "metadata": {},
   "source": [
    "## 12. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd1612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(pearson_corrs, bins=20, alpha=0.7, label='Pearson')\n",
    "plt.hist(spearman_corrs, bins=20, alpha=0.7, label='Spearman')\n",
    "plt.xlabel('Correlation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Per-dimension Correlation Distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots for first few dimensions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(min(6, ground_truth.shape[1])):\n",
    "    ax = axes[i]\n",
    "    ax.scatter(ground_truth[:, i], predictions[:, i], alpha=0.6, s=1)\n",
    "    \n",
    "    # Add perfect prediction line\n",
    "    min_val = min(ground_truth[:, i].min(), predictions[:, i].min())\n",
    "    max_val = max(ground_truth[:, i].max(), predictions[:, i].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel(f'True ADT Embedding Dim {i+1}')\n",
    "    ax.set_ylabel(f'Predicted ADT Embedding Dim {i+1}')\n",
    "    ax.set_title(f'Dim {i+1}: r={pearson_corrs[i]:.3f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28abab3",
   "metadata": {},
   "source": [
    "## 13. Compare with MLP Model (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3117e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load MLP model results if available\n",
    "try:\n",
    "    mlp_results = np.load('mapping_predictions.npz')\n",
    "    mlp_predictions = mlp_results['predictions']\n",
    "    mlp_ground_truth = mlp_results['ground_truth']\n",
    "    mlp_pearson = mlp_results['pearson_corrs']\n",
    "    mlp_spearman = mlp_results['spearman_corrs']\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mlp_mse = mean_squared_error(mlp_ground_truth, mlp_predictions)\n",
    "    mlp_r2 = r2_score(mlp_ground_truth, mlp_predictions)\n",
    "    mlp_mean_pearson = np.mean(mlp_pearson)\n",
    "    mlp_mean_spearman = np.mean(mlp_spearman)\n",
    "    \n",
    "    # Compare results\n",
    "    print(\"\\n=== Transformer vs MLP Comparison ===\")\n",
    "    print(f\"MSE: Transformer: {mse:.6f}, MLP: {mlp_mse:.6f}, Improvement: {(mlp_mse-mse)/mlp_mse*100:.2f}%\")\n",
    "    print(f\"R²: Transformer: {r2:.4f}, MLP: {mlp_r2:.4f}, Improvement: {(r2-mlp_r2)/mlp_r2*100:.2f}%\")\n",
    "    print(f\"Pearson: Transformer: {mean_pearson:.4f}, MLP: {mlp_mean_pearson:.4f}, Improvement: {(mean_pearson-mlp_mean_pearson)/mlp_mean_pearson*100:.2f}%\")\n",
    "    print(f\"Spearman: Transformer: {mean_spearman:.4f}, MLP: {mlp_mean_spearman:.4f}, Improvement: {(mean_spearman-mlp_mean_spearman)/mlp_mean_spearman*100:.2f}%\")\n",
    "    \n",
    "    # Visualize correlation distribution comparison\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(pearson_corrs, bins=20, alpha=0.7, label='Transformer')\n",
    "    plt.hist(mlp_pearson, bins=20, alpha=0.7, label='MLP')\n",
    "    plt.xlabel('Pearson Correlation')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Pearson Correlation Comparison')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(spearman_corrs, bins=20, alpha=0.7, label='Transformer')\n",
    "    plt.hist(mlp_spearman, bins=20, alpha=0.7, label='MLP')\n",
    "    plt.xlabel('Spearman Correlation')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Spearman Correlation Comparison')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"MLP results file not found. Cannot compare models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d1875d",
   "metadata": {},
   "source": [
    "## 14. Save Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained models\n",
    "torch.save({\n",
    "    'rna_gat_state_dict': rna_gat_model.state_dict(),\n",
    "    'adt_gat_state_dict': adt_gat_model.state_dict(),\n",
    "    'transformer_mapping_state_dict': transformer_model.state_dict(),\n",
    "    'rna_input_dim': input_dim,\n",
    "    'adt_output_dim': output_dim,\n",
    "    'test_results': {\n",
    "        'mse': mse,\n",
    "        'r2': r2,\n",
    "        'mean_pearson': mean_pearson,\n",
    "        'mean_spearman': mean_spearman,\n",
    "        'pearson_corrs': pearson_corrs,\n",
    "        'spearman_corrs': spearman_corrs\n",
    "    }\n",
    "}, 'rna_adt_transformer_mapping_models.pth')\n",
    "\n",
    "print(\"Models and results saved to 'rna_adt_transformer_mapping_models.pth'\")\n",
    "\n",
    "# Save predictions for further analysis\n",
    "np.savez('transformer_mapping_predictions.npz', \n",
    "         predictions=predictions, \n",
    "         ground_truth=ground_truth,\n",
    "         pearson_corrs=pearson_corrs,\n",
    "         spearman_corrs=spearman_corrs)\n",
    "\n",
    "print(\"Predictions saved to 'transformer_mapping_predictions.npz'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf2327",
   "metadata": {},
   "source": [
    "## 15. Evaluate Cluster Preservation\n",
    "\n",
    "To further evaluate the quality of the transformer encoder mapping, we can check if the predicted ADT embeddings preserve the cluster structure of the original ADT data. We'll apply Leiden clustering to both the true ADT embeddings and predicted ADT embeddings, then measure the agreement between these cluster assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf0ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AnnData objects for true and predicted ADT embeddings\n",
    "import anndata as ad\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "import scanpy as sc\n",
    "\n",
    "print(\"Evaluating cluster preservation in predicted embeddings...\")\n",
    "\n",
    "# Create AnnData objects\n",
    "true_adt_adata = ad.AnnData(X=ground_truth)\n",
    "pred_adt_adata = ad.AnnData(X=predictions)\n",
    "\n",
    "# Process both datasets the same way\n",
    "for adata in [true_adt_adata, pred_adt_adata]:\n",
    "    sc.pp.neighbors(adata, n_neighbors=15, use_rep='X')\n",
    "    \n",
    "# Run Leiden clustering with multiple resolutions\n",
    "resolutions = [0.2, 0.5, 0.8, 1.0, 1.5, 2.0]\n",
    "results = []\n",
    "\n",
    "for res in resolutions:\n",
    "    # Cluster true ADT embeddings\n",
    "    sc.tl.leiden(true_adt_adata, resolution=res, key_added=f'leiden_res{res}')\n",
    "    \n",
    "    # Cluster predicted ADT embeddings\n",
    "    sc.tl.leiden(pred_adt_adata, resolution=res, key_added=f'leiden_res{res}')\n",
    "    \n",
    "    # Get cluster labels\n",
    "    true_labels = true_adt_adata.obs[f'leiden_res{res}'].astype(int).values\n",
    "    pred_labels = pred_adt_adata.obs[f'leiden_res{res}'].astype(int).values\n",
    "    \n",
    "    # Calculate metrics\n",
    "    ari = adjusted_rand_score(true_labels, pred_labels)\n",
    "    nmi = normalized_mutual_info_score(true_labels, pred_labels, average_method='arithmetic')\n",
    "    \n",
    "    # Number of clusters\n",
    "    true_n_clusters = len(np.unique(true_labels))\n",
    "    pred_n_clusters = len(np.unique(pred_labels))\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Resolution': res,\n",
    "        'True Clusters': true_n_clusters,\n",
    "        'Predicted Clusters': pred_n_clusters,\n",
    "        'ARI': ari,\n",
    "        'NMI': nmi\n",
    "    })\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(results_df['Resolution'], results_df['ARI'], 'o-', label='ARI')\n",
    "plt.plot(results_df['Resolution'], results_df['NMI'], 'o-', label='NMI')\n",
    "plt.xlabel('Leiden Resolution')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Clustering Agreement Metrics')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(resolutions))\n",
    "plt.bar(x - bar_width/2, results_df['True Clusters'], bar_width, label='True ADT')\n",
    "plt.bar(x + bar_width/2, results_df['Predicted Clusters'], bar_width, label='Predicted ADT')\n",
    "plt.xlabel('Leiden Resolution')\n",
    "plt.ylabel('Number of Clusters')\n",
    "plt.title('Cluster Counts')\n",
    "plt.xticks(x, resolutions)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Use resolution with best ARI score for UMAP visualization\n",
    "best_res_idx = results_df['ARI'].idxmax()\n",
    "best_res = results_df.loc[best_res_idx, 'Resolution']\n",
    "print(f\"\\nBest resolution: {best_res} (ARI: {results_df.loc[best_res_idx, 'ARI']:.4f})\")\n",
    "\n",
    "# UMAP visualization of both embeddings with cluster labels\n",
    "for adata in [true_adt_adata, pred_adt_adata]:\n",
    "    sc.tl.umap(adata)\n",
    "\n",
    "# Create a figure for UMAP visualization\n",
    "plt.figure(figsize=(16, 7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sc.pl.umap(true_adt_adata, color=f'leiden_res{best_res}', title='True ADT Embeddings', show=False, legend_loc='on data')\n",
    "plt.axis('on')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sc.pl.umap(pred_adt_adata, color=f'leiden_res{best_res}', title='Predicted ADT Embeddings', show=False, legend_loc='on data')\n",
    "plt.axis('on')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b0479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix to see how well clusters match between true and predicted embeddings\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Get cluster labels at the best resolution\n",
    "best_res = results_df.loc[results_df['ARI'].idxmax(), 'Resolution']\n",
    "true_labels = true_adt_adata.obs[f'leiden_res{best_res}'].astype(int)\n",
    "pred_labels = pred_adt_adata.obs[f'leiden_res{best_res}'].astype(int)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
    "\n",
    "# Get the number of clusters for proper visualization\n",
    "n_clusters_true = len(np.unique(true_labels))\n",
    "n_clusters_pred = len(np.unique(pred_labels))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_matrix, cmap=\"YlGnBu\", annot=True if n_clusters_true <= 20 else False,\n",
    "            fmt='.2f', xticklabels=range(n_clusters_pred), yticklabels=range(n_clusters_true))\n",
    "plt.xlabel('Predicted Clusters')\n",
    "plt.ylabel('True Clusters')\n",
    "plt.title(f'Confusion Matrix (Normalized) - Resolution {best_res}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find the most preserved and least preserved clusters\n",
    "cluster_preservation = np.max(conf_matrix, axis=1)\n",
    "most_preserved_idx = np.argmax(cluster_preservation)\n",
    "least_preserved_idx = np.argmin(cluster_preservation)\n",
    "\n",
    "print(f\"Most preserved cluster: {most_preserved_idx} with {cluster_preservation[most_preserved_idx]:.2%} preservation\")\n",
    "print(f\"Least preserved cluster: {least_preserved_idx} with {cluster_preservation[least_preserved_idx]:.2%} preservation\")\n",
    "\n",
    "# Add cluster labels to the original data for further analysis\n",
    "adata_combined = ad.AnnData(\n",
    "    X=np.concatenate([ground_truth, predictions]),\n",
    "    obs=pd.DataFrame({\n",
    "        'embedding_type': ['True ADT'] * ground_truth.shape[0] + ['Predicted ADT'] * predictions.shape[0],\n",
    "    })\n",
    ")\n",
    "\n",
    "# Calculate UMAP for the combined embedding space\n",
    "sc.pp.neighbors(adata_combined, n_neighbors=15, use_rep='X')\n",
    "sc.tl.umap(adata_combined)\n",
    "\n",
    "# Plot combined UMAP\n",
    "plt.figure(figsize=(12, 10))\n",
    "sc.pl.umap(adata_combined, color='embedding_type', title='Combined UMAP - True vs Predicted ADT Embeddings',\n",
    "           palette={'True ADT': 'blue', 'Predicted ADT': 'red'}, alpha=0.7, size=30, show=False)\n",
    "plt.legend(loc='upper right', frameon=True)\n",
    "plt.show()\n",
    "\n",
    "# Quantify global structure preservation\n",
    "from scipy.spatial import procrustes\n",
    "\n",
    "# Perform Procrustes analysis on UMAP coordinates\n",
    "true_coords = true_adt_adata.obsm['X_umap']\n",
    "pred_coords = pred_adt_adata.obsm['X_umap']\n",
    "\n",
    "# Procrustes analysis scales, rotates and translates the predicted coordinates to best match the true coordinates\n",
    "mtx1, mtx2, disparity = procrustes(true_coords, pred_coords)\n",
    "\n",
    "print(f\"\\nProcrustes analysis disparity (lower is better): {disparity:.4f}\")\n",
    "print(\"This value quantifies how well the global structure is preserved after optimal alignment.\")\n",
    "\n",
    "# Calculate silhouette scores to measure cluster quality\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "try:\n",
    "    true_silhouette = silhouette_score(true_adt_adata.X, true_labels)\n",
    "    pred_silhouette = silhouette_score(pred_adt_adata.X, pred_labels)\n",
    "    \n",
    "    print(f\"\\nSilhouette score for true clusters: {true_silhouette:.4f}\")\n",
    "    print(f\"Silhouette score for predicted clusters: {pred_silhouette:.4f}\")\n",
    "    print(f\"Ratio (pred/true): {pred_silhouette/true_silhouette:.4f}\")\n",
    "    if pred_silhouette >= true_silhouette:\n",
    "        print(\"The predicted embeddings have equally good or better defined clusters than the true embeddings.\")\n",
    "    else:\n",
    "        print(\"The true embeddings have better defined clusters than the predicted embeddings.\")\n",
    "except:\n",
    "    print(\"Could not calculate silhouette scores, possibly due to cluster numbers or sample size.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c0a170",
   "metadata": {},
   "source": [
    "## 17. Comprehensive Performance Visualization\n",
    "\n",
    "In this section, we'll create additional visualizations to better understand the model performance and assess the quality of the RNA to ADT mapping:\n",
    "\n",
    "1. Detailed accuracy metrics and correlation heatmaps\n",
    "2. Dimension reduction visualizations comparing true vs. predicted embeddings\n",
    "3. Feature importance analysis\n",
    "4. Distribution of prediction errors\n",
    "5. Performance across different cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3603971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Detailed Accuracy Metrics and Correlation Heatmap\n",
    "\n",
    "# Calculate per-dimension metrics\n",
    "dim_metrics = []\n",
    "for i in range(ground_truth.shape[1]):\n",
    "    true = ground_truth[:, i]\n",
    "    pred = predictions[:, i]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    dim_mse = mean_squared_error(true, pred)\n",
    "    dim_r2 = r2_score(true, pred)\n",
    "    dim_pearson, _ = pearsonr(true, pred)\n",
    "    dim_spearman, _ = spearmanr(true, pred)\n",
    "    \n",
    "    # Calculate relative error\n",
    "    mean_abs_error = np.mean(np.abs(true - pred))\n",
    "    mean_true = np.mean(np.abs(true))\n",
    "    rel_error = mean_abs_error / mean_true if mean_true > 0 else float('inf')\n",
    "    \n",
    "    dim_metrics.append({\n",
    "        'Dimension': i + 1,\n",
    "        'MSE': dim_mse,\n",
    "        'R²': dim_r2,\n",
    "        'Pearson r': dim_pearson,\n",
    "        'Spearman r': dim_spearman,\n",
    "        'Relative Error': rel_error\n",
    "    })\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "metrics_df = pd.DataFrame(dim_metrics)\n",
    "\n",
    "# Sort by correlation to identify best and worst predicted dimensions\n",
    "metrics_df_sorted = metrics_df.sort_values(by='Pearson r', ascending=False)\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Summary Statistics for Dimension-wise Performance:\")\n",
    "print(metrics_df.describe())\n",
    "\n",
    "# Plot distribution of metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# MSE distribution\n",
    "sns.histplot(metrics_df['MSE'], kde=True, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('MSE Distribution Across Dimensions')\n",
    "axes[0, 0].set_xlabel('Mean Squared Error')\n",
    "\n",
    "# R² distribution\n",
    "sns.histplot(metrics_df['R²'], kde=True, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('R² Distribution Across Dimensions')\n",
    "axes[0, 1].set_xlabel('R² Score')\n",
    "\n",
    "# Pearson correlation distribution\n",
    "sns.histplot(metrics_df['Pearson r'], kde=True, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Pearson Correlation Distribution')\n",
    "axes[1, 0].set_xlabel('Pearson r')\n",
    "\n",
    "# Relative error distribution\n",
    "sns.histplot(metrics_df['Relative Error'].clip(upper=2), kde=True, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Relative Error Distribution (clipped at 2)')\n",
    "axes[1, 1].set_xlabel('Relative Error')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display top 10 best and worst predicted dimensions\n",
    "print(\"\\nTop 10 Best Predicted Dimensions:\")\n",
    "display(metrics_df_sorted.head(10))\n",
    "\n",
    "print(\"\\nTop 10 Worst Predicted Dimensions:\")\n",
    "display(metrics_df_sorted.tail(10))\n",
    "\n",
    "# Calculate correlation between predicted and true dimensions\n",
    "corr_matrix = np.zeros((ground_truth.shape[1], ground_truth.shape[1]))\n",
    "for i in range(ground_truth.shape[1]):\n",
    "    for j in range(ground_truth.shape[1]):\n",
    "        corr_matrix[i, j], _ = pearsonr(ground_truth[:, i], predictions[:, j])\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', center=0, \n",
    "            xticklabels=range(1, ground_truth.shape[1]+1, 5), \n",
    "            yticklabels=range(1, ground_truth.shape[1]+1, 5))\n",
    "plt.title('Correlation Between True and Predicted Dimensions')\n",
    "plt.xlabel('Predicted Dimension')\n",
    "plt.ylabel('True Dimension')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot diagonal correlation strength\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, ground_truth.shape[1]+1), np.diag(corr_matrix), 'o-')\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.7)\n",
    "plt.axhline(y=0.7, color='g', linestyle='--', alpha=0.7)\n",
    "plt.title('Diagonal Correlation Strength')\n",
    "plt.xlabel('Dimension')\n",
    "plt.ylabel('Correlation (r)')\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3532ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dimension Reduction Visualizations\n",
    "\n",
    "# Combine true and predicted embeddings for unified visualization\n",
    "combined_data = np.vstack([ground_truth, predictions])\n",
    "data_labels = np.array(['True ADT'] * ground_truth.shape[0] + ['Predicted ADT'] * predictions.shape[0])\n",
    "\n",
    "# Create color palette\n",
    "palette = {'True ADT': '#1f77b4', 'Predicted ADT': '#ff7f0e'}\n",
    "\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(combined_data)\n",
    "\n",
    "# Extract coordinates for each group\n",
    "pca_df = pd.DataFrame({\n",
    "    'PC1': pca_result[:, 0],\n",
    "    'PC2': pca_result[:, 1],\n",
    "    'Type': data_labels\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# PCA plot\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.scatterplot(\n",
    "    data=pca_df, x='PC1', y='PC2', hue='Type', \n",
    "    palette=palette, s=10, alpha=0.7\n",
    ")\n",
    "plt.title(f'PCA Projection\\nExplained Variance: {pca.explained_variance_ratio_.sum():.2f}')\n",
    "\n",
    "# t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# This can be slow on large datasets, so we'll use a sample if needed\n",
    "max_samples = 5000\n",
    "if combined_data.shape[0] > max_samples:\n",
    "    sample_idx = np.random.choice(combined_data.shape[0], max_samples, replace=False)\n",
    "    sample_data = combined_data[sample_idx]\n",
    "    sample_labels = data_labels[sample_idx]\n",
    "else:\n",
    "    sample_data = combined_data\n",
    "    sample_labels = data_labels\n",
    "\n",
    "try:\n",
    "    tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)\n",
    "    tsne_result = tsne.fit_transform(sample_data)\n",
    "    \n",
    "    # Extract coordinates for each group\n",
    "    tsne_df = pd.DataFrame({\n",
    "        'tSNE1': tsne_result[:, 0],\n",
    "        'tSNE2': tsne_result[:, 1],\n",
    "        'Type': sample_labels\n",
    "    })\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.scatterplot(\n",
    "        data=tsne_df, x='tSNE1', y='tSNE2', hue='Type', \n",
    "        palette=palette, s=10, alpha=0.7\n",
    "    )\n",
    "    plt.title('t-SNE Projection')\n",
    "except Exception as e:\n",
    "    print(f\"t-SNE failed: {e}\")\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.text(0.5, 0.5, f\"t-SNE failed: {str(e)}\", \n",
    "             ha='center', va='center', transform=plt.gca().transAxes)\n",
    "\n",
    "# UMAP (if available)\n",
    "try:\n",
    "    import umap\n",
    "    \n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    umap_result = reducer.fit_transform(sample_data)\n",
    "    \n",
    "    # Extract coordinates for each group\n",
    "    umap_df = pd.DataFrame({\n",
    "        'UMAP1': umap_result[:, 0],\n",
    "        'UMAP2': umap_result[:, 1],\n",
    "        'Type': sample_labels\n",
    "    })\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.scatterplot(\n",
    "        data=umap_df, x='UMAP1', y='UMAP2', hue='Type', \n",
    "        palette=palette, s=10, alpha=0.7\n",
    "    )\n",
    "    plt.title('UMAP Projection')\n",
    "except ImportError:\n",
    "    print(\"UMAP not available. Install with 'pip install umap-learn'\")\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.text(0.5, 0.5, \"UMAP not installed\\nInstall with 'pip install umap-learn'\", \n",
    "             ha='center', va='center', transform=plt.gca().transAxes)\n",
    "except Exception as e:\n",
    "    print(f\"UMAP failed: {e}\")\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.text(0.5, 0.5, f\"UMAP failed: {str(e)}\", \n",
    "             ha='center', va='center', transform=plt.gca().transAxes)\n",
    "\n",
    "# Procrustes analysis - align predicted to true embeddings\n",
    "from scipy.spatial import procrustes\n",
    "\n",
    "# Use sample if data is large\n",
    "if ground_truth.shape[0] > max_samples:\n",
    "    sample_idx = np.random.choice(ground_truth.shape[0], max_samples, replace=False)\n",
    "    true_sample = ground_truth[sample_idx]\n",
    "    pred_sample = predictions[sample_idx]\n",
    "else:\n",
    "    true_sample = ground_truth\n",
    "    pred_sample = predictions\n",
    "\n",
    "# First reduce dimensions with PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "true_pca = pca.fit_transform(true_sample)\n",
    "pred_pca = pca.transform(pred_sample)\n",
    "\n",
    "# Perform Procrustes alignment\n",
    "mtx1, mtx2, disparity = procrustes(true_pca, pred_pca)\n",
    "\n",
    "# Create dataframe for plotting\n",
    "procrustes_df = pd.DataFrame({\n",
    "    'X_True': mtx1[:, 0],\n",
    "    'Y_True': mtx1[:, 1],\n",
    "    'X_Pred': mtx2[:, 0],\n",
    "    'Y_Pred': mtx2[:, 1],\n",
    "})\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "# Plot true points\n",
    "plt.scatter(procrustes_df['X_True'], procrustes_df['Y_True'], \n",
    "            color=palette['True ADT'], s=10, alpha=0.7, label='True ADT')\n",
    "# Plot predicted points\n",
    "plt.scatter(procrustes_df['X_Pred'], procrustes_df['Y_Pred'], \n",
    "            color=palette['Predicted ADT'], s=10, alpha=0.7, label='Predicted ADT')\n",
    "\n",
    "# Draw lines connecting corresponding points\n",
    "for i in range(len(procrustes_df)):\n",
    "    plt.plot([procrustes_df.iloc[i, 0], procrustes_df.iloc[i, 2]],\n",
    "             [procrustes_df.iloc[i, 1], procrustes_df.iloc[i, 3]],\n",
    "             'gray', alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f'Procrustes Analysis\\nDisparity: {disparity:.4f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565df71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Importance Analysis\n",
    "\n",
    "# 3.1 Dimension-wise error analysis\n",
    "error_magnitude = np.mean(np.abs(ground_truth - predictions), axis=0)\n",
    "\n",
    "# Plot dimensions sorted by prediction error\n",
    "plt.figure(figsize=(12, 6))\n",
    "sorted_indices = np.argsort(error_magnitude)\n",
    "plt.bar(range(len(error_magnitude)), error_magnitude[sorted_indices], alpha=0.7)\n",
    "plt.xlabel('Dimension Index (Sorted by Error)')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Dimension-wise Prediction Error')\n",
    "plt.grid(alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3.2 Variance explained analysis\n",
    "# Calculate variance explained by each dimension\n",
    "true_variance = np.var(ground_truth, axis=0)\n",
    "pred_variance = np.var(predictions, axis=0)\n",
    "variance_ratio = pred_variance / true_variance\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "var_df = pd.DataFrame({\n",
    "    'Dimension': range(1, len(true_variance) + 1),\n",
    "    'True Variance': true_variance,\n",
    "    'Predicted Variance': pred_variance,\n",
    "    'Variance Ratio': variance_ratio,\n",
    "    'Error': error_magnitude\n",
    "})\n",
    "\n",
    "# Plot variance comparison\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.scatter(var_df['True Variance'], var_df['Predicted Variance'], alpha=0.7)\n",
    "plt.plot([0, var_df['True Variance'].max()], [0, var_df['True Variance'].max()], 'r--')\n",
    "plt.xlabel('True Variance')\n",
    "plt.ylabel('Predicted Variance')\n",
    "plt.title('Variance Preservation in Predicted Embeddings')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.histplot(var_df['Variance Ratio'].clip(0, 2), bins=30, kde=True)\n",
    "plt.axvline(x=1, color='r', linestyle='--')\n",
    "plt.xlabel('Variance Ratio (Predicted/True)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Variance Ratios (clipped at 2)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3.3 Analyze relationship between variance and prediction error\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(var_df['True Variance'], var_df['Error'], alpha=0.7)\n",
    "plt.xlabel('True Variance')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Relationship Between Dimension Variance and Prediction Error')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Add best fit line\n",
    "from scipy.stats import linregress\n",
    "slope, intercept, r_value, p_value, std_err = linregress(var_df['True Variance'], var_df['Error'])\n",
    "x_line = np.linspace(var_df['True Variance'].min(), var_df['True Variance'].max(), 100)\n",
    "y_line = slope * x_line + intercept\n",
    "plt.plot(x_line, y_line, 'r--', \n",
    "         label=f'Slope: {slope:.4f}, R²: {r_value**2:.4f}, p: {p_value:.4f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display top dimensions by variance\n",
    "print(\"\\nTop 10 Dimensions by Variance:\")\n",
    "display(var_df.sort_values(by='True Variance', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Distribution of Prediction Errors\n",
    "\n",
    "# Calculate errors\n",
    "absolute_errors = np.abs(ground_truth - predictions)\n",
    "relative_errors = np.zeros_like(absolute_errors)\n",
    "non_zero_mask = (ground_truth != 0)\n",
    "relative_errors[non_zero_mask] = absolute_errors[non_zero_mask] / np.abs(ground_truth)[non_zero_mask]\n",
    "\n",
    "# Aggregate errors per sample\n",
    "sample_mae = np.mean(absolute_errors, axis=1)  # Mean absolute error per sample\n",
    "sample_max_error = np.max(absolute_errors, axis=1)  # Max error per sample\n",
    "sample_mean_rel_error = np.mean(np.clip(relative_errors, 0, 2), axis=1)  # Mean relative error, clipped at 2\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "error_df = pd.DataFrame({\n",
    "    'Mean Absolute Error': sample_mae,\n",
    "    'Max Absolute Error': sample_max_error,\n",
    "    'Mean Relative Error': sample_mean_rel_error\n",
    "})\n",
    "\n",
    "# Visualize error distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Mean absolute error histogram\n",
    "sns.histplot(error_df['Mean Absolute Error'], kde=True, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Distribution of Mean Absolute Errors per Sample')\n",
    "axes[0, 0].set_xlabel('Mean Absolute Error')\n",
    "\n",
    "# Max absolute error histogram\n",
    "sns.histplot(error_df['Max Absolute Error'], kde=True, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Distribution of Maximum Absolute Errors per Sample')\n",
    "axes[0, 1].set_xlabel('Maximum Absolute Error')\n",
    "\n",
    "# Mean relative error histogram\n",
    "sns.histplot(error_df['Mean Relative Error'], kde=True, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Distribution of Mean Relative Errors per Sample')\n",
    "axes[1, 0].set_xlabel('Mean Relative Error (clipped at 2)')\n",
    "\n",
    "# Scatterplot of mean vs max error\n",
    "sns.scatterplot(x='Mean Absolute Error', y='Max Absolute Error', data=error_df, ax=axes[1, 1], alpha=0.5)\n",
    "axes[1, 1].set_title('Relationship Between Mean and Max Errors')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4.2 Analyze error distribution by dimension\n",
    "# Create box plot showing error distribution for top dimensions\n",
    "# Select a subset of dimensions for clarity\n",
    "n_dims_to_show = min(20, ground_truth.shape[1])\n",
    "top_var_dims = var_df.sort_values(by='True Variance', ascending=False).head(n_dims_to_show)['Dimension'].values - 1\n",
    "\n",
    "# Extract errors for these dimensions\n",
    "selected_errors = absolute_errors[:, top_var_dims]\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "boxplot_data = []\n",
    "for i, dim_idx in enumerate(top_var_dims):\n",
    "    boxplot_data.append(pd.DataFrame({\n",
    "        'Absolute Error': absolute_errors[:, dim_idx],\n",
    "        'Dimension': f\"Dim {dim_idx+1}\"\n",
    "    }))\n",
    "\n",
    "boxplot_df = pd.concat(boxplot_data)\n",
    "\n",
    "# Create box plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x='Dimension', y='Absolute Error', data=boxplot_df)\n",
    "plt.title('Error Distribution for Top High-Variance Dimensions')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4.3 Identify and analyze outlier predictions\n",
    "# Find samples with the highest prediction errors\n",
    "worst_samples_idx = np.argsort(sample_mae)[-20:]  # Get indices of 20 worst predictions\n",
    "worst_samples_true = ground_truth[worst_samples_idx]\n",
    "worst_samples_pred = predictions[worst_samples_idx]\n",
    "\n",
    "# Display mean error for worst samples\n",
    "print(f\"Mean absolute error for 20 worst predictions: {sample_mae[worst_samples_idx].mean():.4f}\")\n",
    "print(f\"(Compared to overall mean absolute error: {sample_mae.mean():.4f})\")\n",
    "\n",
    "# Plot some of the worst sample predictions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle(\"Examples of Worst Predictions\", fontsize=16)\n",
    "\n",
    "axes = axes.flatten()\n",
    "for i, idx in enumerate(worst_samples_idx[-4:]):  # Show 4 worst samples\n",
    "    true = ground_truth[idx]\n",
    "    pred = predictions[idx]\n",
    "    dims = min(50, len(true))  # Show first 50 dimensions or fewer\n",
    "    \n",
    "    ax = axes[i]\n",
    "    x = range(dims)\n",
    "    ax.plot(x, true[:dims], 'b-', label='True', alpha=0.7)\n",
    "    ax.plot(x, pred[:dims], 'r-', label='Predicted', alpha=0.7)\n",
    "    ax.set_title(f\"Sample #{idx}: MAE={sample_mae[idx]:.4f}\")\n",
    "    ax.set_xlabel('Dimension')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)  # Adjust for the suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe6bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Performance Across Different Cell Types (Clusters)\n",
    "\n",
    "# Assuming we have leiden clusters from earlier analysis\n",
    "# We'll use these to analyze prediction performance by cell type\n",
    "\n",
    "# 5.1 Re-create predictions and ground truth with cell type information\n",
    "try:\n",
    "    # Get cluster labels if available\n",
    "    # First check if we can use leiden labels from trainADT\n",
    "    if 'leiden' in trainADT.obs:\n",
    "        # Need to map back to the test indices\n",
    "        all_indices = np.arange(len(trainADT))\n",
    "        cluster_labels = trainADT.obs['leiden'].values[all_indices[test_mask_np]]\n",
    "        \n",
    "        # Create DataFrame with predictions, ground truth, and cluster info\n",
    "        cell_type_df = pd.DataFrame({\n",
    "            'Cluster': cluster_labels,\n",
    "            'Mean Absolute Error': sample_mae\n",
    "        })\n",
    "        \n",
    "        # Calculate average error by cell type\n",
    "        cluster_performance = cell_type_df.groupby('Cluster')['Mean Absolute Error'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        cluster_performance = cluster_performance.sort_values(by='mean')\n",
    "        \n",
    "        # Plot performance by cell type\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        sns.barplot(x='Cluster', y='mean', data=cluster_performance, \n",
    "                    order=cluster_performance['Cluster'])\n",
    "        plt.errorbar(x=range(len(cluster_performance)), \n",
    "                    y=cluster_performance['mean'], \n",
    "                    yerr=cluster_performance['std'],\n",
    "                    fmt='none', ecolor='black', capsize=3)\n",
    "        plt.xlabel('Cell Type (Cluster)')\n",
    "        plt.ylabel('Mean Absolute Error')\n",
    "        plt.title('Model Performance by Cell Type')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Show detailed performance by cluster\n",
    "        print(\"Performance by Cell Type:\")\n",
    "        display(cluster_performance.sort_values(by='mean'))\n",
    "        \n",
    "        # Create a UMAP visualization with error overlay\n",
    "        if 'X_umap' in trainADT.obsm:\n",
    "            # Get UMAP coordinates for test data\n",
    "            test_umap = trainADT.obsm['X_umap'][all_indices[test_mask_np]]\n",
    "            \n",
    "            # Create DataFrame for plotting\n",
    "            umap_df = pd.DataFrame({\n",
    "                'UMAP1': test_umap[:, 0],\n",
    "                'UMAP2': test_umap[:, 1],\n",
    "                'Cluster': cluster_labels,\n",
    "                'Error': sample_mae\n",
    "            })\n",
    "            \n",
    "            # Plot UMAP colored by cluster\n",
    "            plt.figure(figsize=(16, 7))\n",
    "            \n",
    "            plt.subplot(1, 2, 1)\n",
    "            sns.scatterplot(x='UMAP1', y='UMAP2', hue='Cluster', data=umap_df, \n",
    "                            palette='tab20', s=10, alpha=0.7)\n",
    "            plt.title('UMAP Projection by Cell Type')\n",
    "            \n",
    "            # Plot UMAP colored by prediction error\n",
    "            plt.subplot(1, 2, 2)\n",
    "            scatter = plt.scatter(umap_df['UMAP1'], umap_df['UMAP2'], \n",
    "                                 c=umap_df['Error'], cmap='viridis', \n",
    "                                 s=10, alpha=0.7)\n",
    "            plt.colorbar(scatter, label='Mean Absolute Error')\n",
    "            plt.title('UMAP Projection by Prediction Error')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Statistical test for differences between clusters\n",
    "            from scipy.stats import kruskal\n",
    "            \n",
    "            try:\n",
    "                # Kruskal-Wallis H-test for independent samples\n",
    "                h_stat, p_value = kruskal(*[\n",
    "                    cell_type_df[cell_type_df['Cluster'] == c]['Mean Absolute Error'].values \n",
    "                    for c in cell_type_df['Cluster'].unique()\n",
    "                ])\n",
    "                \n",
    "                print(f\"\\nKruskal-Wallis test for differences between clusters:\")\n",
    "                print(f\"H-statistic: {h_stat:.4f}, p-value: {p_value:.4e}\")\n",
    "                \n",
    "                if p_value < 0.05:\n",
    "                    print(\"There are statistically significant differences in performance between cell types\")\n",
    "                else:\n",
    "                    print(\"No statistically significant differences in performance between cell types\")\n",
    "            except:\n",
    "                print(\"Could not perform statistical test - possibly due to insufficient data in some clusters\")\n",
    "    else:\n",
    "        print(\"No cluster information available - cannot analyze performance by cell type\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not analyze performance by cell type: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# 5.2 Visualize combined data with error overlay using PCA\n",
    "# Create PCA projection of the test data\n",
    "pca = PCA(n_components=2)\n",
    "test_pca = pca.fit_transform(np.vstack([ground_truth, predictions]))\n",
    "\n",
    "# Split back into true and predicted\n",
    "n_test = ground_truth.shape[0]\n",
    "true_pca = test_pca[:n_test]\n",
    "pred_pca = test_pca[n_test:]\n",
    "\n",
    "# Create a scatter plot with lines connecting true and predicted points\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_test):\n",
    "    # Draw line from true to predicted\n",
    "    plt.plot([true_pca[i, 0], pred_pca[i, 0]], \n",
    "             [true_pca[i, 1], pred_pca[i, 1]], \n",
    "             'gray', alpha=0.1)\n",
    "\n",
    "# Plot points with error coloring\n",
    "scatter = plt.scatter(true_pca[:, 0], true_pca[:, 1], c=sample_mae, \n",
    "                     cmap='viridis', s=30, alpha=0.7)\n",
    "plt.colorbar(scatter, label='Mean Absolute Error')\n",
    "\n",
    "# Add predicted points in red\n",
    "plt.scatter(pred_pca[:, 0], pred_pca[:, 1], c='red', s=5, alpha=0.5)\n",
    "\n",
    "plt.title('PCA Projection with Error Overlay and Prediction Lines')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.3 Create a summary performance table\n",
    "performance_summary = pd.DataFrame({\n",
    "    'Metric': ['Overall MSE', 'R² Score', 'Mean Pearson Correlation', 'Mean Spearman Correlation'],\n",
    "    'Value': [mse, r2, mean_pearson, mean_spearman]\n",
    "})\n",
    "\n",
    "# Add percentiles of error\n",
    "percentiles = [10, 25, 50, 75, 90]\n",
    "for p in percentiles:\n",
    "    performance_summary = performance_summary.append({\n",
    "        'Metric': f'MAE {p}th Percentile',\n",
    "        'Value': np.percentile(sample_mae, p)\n",
    "    }, ignore_index=True)\n",
    "\n",
    "print(\"Overall Performance Summary:\")\n",
    "display(performance_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c2c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create Interactive Visualizations (using Plotly if available)\n",
    "\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    \n",
    "    # Create interactive PCA plot\n",
    "    pca = PCA(n_components=3)\n",
    "    pca_result = pca.fit_transform(combined_data)\n",
    "    \n",
    "    # Extract coordinates for each group\n",
    "    pca_df = pd.DataFrame({\n",
    "        'PC1': pca_result[:, 0],\n",
    "        'PC2': pca_result[:, 1],\n",
    "        'PC3': pca_result[:, 2],\n",
    "        'Type': data_labels\n",
    "    })\n",
    "    \n",
    "    # Add error information to predicted points\n",
    "    n_test = ground_truth.shape[0]\n",
    "    for i, mae in enumerate(sample_mae):\n",
    "        idx = n_test + i  # Index in the combined data\n",
    "        pca_df.loc[idx, 'Error'] = mae\n",
    "    \n",
    "    # Create interactive 3D PCA plot\n",
    "    fig = px.scatter_3d(\n",
    "        pca_df, x='PC1', y='PC2', z='PC3',\n",
    "        color='Type', symbol='Type',\n",
    "        opacity=0.7,\n",
    "        labels={'PC1': f'PC1 ({pca.explained_variance_ratio_[0]:.2%})',\n",
    "                'PC2': f'PC2 ({pca.explained_variance_ratio_[1]:.2%})',\n",
    "                'PC3': f'PC3 ({pca.explained_variance_ratio_[2]:.2%})'},\n",
    "        title='Interactive 3D PCA Projection',\n",
    "        height=700\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=3))\n",
    "    fig.show()\n",
    "    \n",
    "    # Create interactive error heatmap for dimensions\n",
    "    # Calculate correlation matrix between predicted and true dimensions\n",
    "    interactive_corr_matrix = np.zeros((min(30, ground_truth.shape[1]), min(30, ground_truth.shape[1])))\n",
    "    for i in range(interactive_corr_matrix.shape[0]):\n",
    "        for j in range(interactive_corr_matrix.shape[1]):\n",
    "            interactive_corr_matrix[i, j], _ = pearsonr(ground_truth[:, i], predictions[:, j])\n",
    "    \n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=interactive_corr_matrix,\n",
    "        x=[f'Pred {i+1}' for i in range(interactive_corr_matrix.shape[1])],\n",
    "        y=[f'True {i+1}' for i in range(interactive_corr_matrix.shape[0])],\n",
    "        colorscale='RdBu_r',\n",
    "        zmid=0,\n",
    "        colorbar=dict(title='Correlation')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Correlation Between True and Predicted Dimensions (First 30)',\n",
    "        xaxis_title='Predicted Dimension',\n",
    "        yaxis_title='True Dimension',\n",
    "        height=600,\n",
    "        width=700\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Interactive scatter plot showing prediction quality\n",
    "    # Take a sample of points for better performance\n",
    "    max_points = 2000\n",
    "    if ground_truth.shape[0] > max_points:\n",
    "        sample_idx = np.random.choice(ground_truth.shape[0], max_points, replace=False)\n",
    "        gt_sample = ground_truth[sample_idx]\n",
    "        pred_sample = predictions[sample_idx]\n",
    "        error_sample = sample_mae[sample_idx]\n",
    "    else:\n",
    "        gt_sample = ground_truth\n",
    "        pred_sample = predictions\n",
    "        error_sample = sample_mae\n",
    "    \n",
    "    # Get first two PCA components\n",
    "    pca = PCA(n_components=2)\n",
    "    gt_pca = pca.fit_transform(gt_sample)\n",
    "    pred_pca = pca.transform(pred_sample)\n",
    "    \n",
    "    # Create DataFrame for plotting\n",
    "    scatter_df = pd.DataFrame({\n",
    "        'True_PC1': gt_pca[:, 0],\n",
    "        'True_PC2': gt_pca[:, 1],\n",
    "        'Pred_PC1': pred_pca[:, 0],\n",
    "        'Pred_PC2': pred_pca[:, 1],\n",
    "        'Error': error_sample\n",
    "    })\n",
    "    \n",
    "    # Create subplot with two scatterplots\n",
    "    fig = make_subplots(rows=1, cols=2, \n",
    "                        subplot_titles=('True Embeddings', 'Predicted Embeddings'))\n",
    "    \n",
    "    # Add scatter traces\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=scatter_df['True_PC1'], y=scatter_df['True_PC2'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color=scatter_df['Error'],\n",
    "                colorscale='Viridis',\n",
    "                colorbar=dict(title='Error'),\n",
    "                showscale=True\n",
    "            ),\n",
    "            name='True'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=scatter_df['Pred_PC1'], y=scatter_df['Pred_PC2'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color=scatter_df['Error'],\n",
    "                colorscale='Viridis',\n",
    "                showscale=False\n",
    "            ),\n",
    "            name='Predicted'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text=\"PCA Projection with Error Coloring\",\n",
    "        height=500,\n",
    "        width=900\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Plotly is not installed. Install with 'pip install plotly' for interactive visualizations.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating interactive visualizations: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a11eff6",
   "metadata": {},
   "source": [
    "## 18. Model Performance Summary\n",
    "\n",
    "The comprehensive visualizations above provide detailed insights into the performance of our Transformer Encoder model for mapping RNA embeddings to ADT embeddings:\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Overall Performance**:\n",
    "   - MSE (Mean Squared Error): Quantifies the average squared difference between predicted and true values\n",
    "   - R² Score: Indicates how much variance in the true values is captured by the model\n",
    "   - Pearson/Spearman Correlations: Measure the linear and rank correlation between predicted and true values\n",
    "\n",
    "2. **Dimension-wise Analysis**:\n",
    "   - Some embedding dimensions are predicted with higher accuracy than others\n",
    "   - High-variance dimensions tend to be more challenging to predict\n",
    "   - The diagonal correlation heatmap shows how well each individual dimension is preserved\n",
    "\n",
    "3. **Embedding Space Structure**:\n",
    "   - Dimension reduction visualizations (PCA, t-SNE, UMAP) show how well the global structure is preserved\n",
    "   - Procrustes analysis quantifies the alignment between true and predicted embedding spaces\n",
    "   - Connected point visualizations reveal how individual points move in the embedding space\n",
    "\n",
    "4. **Error Analysis**:\n",
    "   - Distribution of errors across samples identifies potential outliers\n",
    "   - Feature importance analysis reveals which dimensions contribute most to errors\n",
    "   - Error patterns across different cell types help identify model weaknesses\n",
    "\n",
    "5. **Cell Type Performance**:\n",
    "   - Performance varies across different cell populations (clusters)\n",
    "   - Some cell types may be easier to predict than others\n",
    "   - Error distribution in UMAP space reveals biological patterns in prediction accuracy\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **High R² and Correlation**: Indicates the model captures most of the variance in the ADT embeddings\n",
    "- **Low MSE**: Suggests precise numerical prediction of embedding values\n",
    "- **Preserved Cluster Structure**: Demonstrates the model maintains the biological meaning in the mapping\n",
    "- **Consistent Performance Across Cell Types**: Shows robustness across diverse biological contexts\n",
    "\n",
    "These visualizations provide a comprehensive assessment of the model's strengths and weaknesses, helping to understand not just how well it performs overall, but where it excels or needs improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d56994e",
   "metadata": {},
   "source": [
    "## 16. Interpretation of Cluster Preservation Results\n",
    "\n",
    "The above analysis helps us understand how well our Transformer Encoder model preserves biological cell types when mapping from RNA to ADT embeddings. Here's how to interpret these results:\n",
    "\n",
    "### Key Metrics:\n",
    "- **Adjusted Rand Index (ARI)**: Measures the similarity between the true and predicted cluster assignments, adjusted for chance. Values range from -1 to 1, where 1 indicates perfect agreement, and values near 0 indicate random clustering.\n",
    "- **Normalized Mutual Information (NMI)**: Quantifies the shared information between the two clusterings. Values range from 0 to 1, with 1 indicating perfect agreement.\n",
    "- **Procrustes Disparity**: Measures how well the global structure is preserved after optimal alignment (lower is better).\n",
    "- **Silhouette Scores**: Measures how well-defined the clusters are (higher is better).\n",
    "\n",
    "### Interpretation Guidelines:\n",
    "\n",
    "1. **Strong Cluster Preservation** (Good model performance):\n",
    "   - High ARI (> 0.7) and NMI (> 0.8)\n",
    "   - Similar number of clusters between true and predicted embeddings\n",
    "   - Low Procrustes disparity\n",
    "   - Similar silhouette scores between true and predicted embeddings\n",
    "   - Clear diagonal pattern in confusion matrix\n",
    "\n",
    "2. **Moderate Cluster Preservation** (Acceptable model performance):\n",
    "   - Moderate ARI (0.4-0.7) and NMI (0.5-0.8)\n",
    "   - Some differences in cluster numbers\n",
    "   - Some off-diagonal elements in confusion matrix, but still showing structure\n",
    "   - Visible separation of clusters in UMAP visualizations, though not identical\n",
    "\n",
    "3. **Poor Cluster Preservation** (Model needs improvement):\n",
    "   - Low ARI (< 0.4) and NMI (< 0.5)\n",
    "   - Very different number of clusters\n",
    "   - No clear pattern in confusion matrix\n",
    "   - Poor separation in UMAP visualizations\n",
    "\n",
    "### Biological Significance:\n",
    "If the model demonstrates good cluster preservation, it suggests that:\n",
    "1. The RNA expression data contains sufficient information to predict cell types as defined by surface protein markers\n",
    "2. The transformer model has successfully learned to map between these two modalities\n",
    "3. The predicted ADT embeddings could potentially be used for downstream analyses in place of actual ADT measurements\n",
    "\n",
    "This evaluation framework provides a comprehensive assessment of how well the model maintains biological cell type structure when mapping between RNA and ADT modalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc402109",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implements a pipeline to learn mappings between GAT embeddings of RNA and ADT data:\n",
    "\n",
    "1. **Data Preprocessing**: Both RNA and ADT data are normalized, scaled, and processed to create neighbor graphs\n",
    "2. **GAT Training**: Separate GAT models are trained on RNA and ADT data for node classification\n",
    "3. **Embedding Extraction**: Intermediate embeddings are extracted from the trained GAT models\n",
    "4. **Transformer Mapping**: \n",
    "   - A Transformer Encoder architecture learns to map RNA embeddings to ADT embeddings\n",
    "   - Self-attention mechanisms capture complex dependencies between embedding dimensions\n",
    "   - Multi-headed attention allows the model to focus on different aspects of the data\n",
    "5. **Evaluation**: The mapping quality is assessed using MSE, R², and correlation metrics\n",
    "\n",
    "The Transformer architecture offers several advantages over MLPs:\n",
    "- **Context awareness**: Self-attention mechanism captures global dependencies in the embeddings\n",
    "- **Parameter efficiency**: Shared parameters across layers for better generalization\n",
    "- **Representation power**: Better handling of complex relationships between features\n",
    "\n",
    "The trained models can be used to predict ADT embeddings from RNA data, enabling cross-modal analysis and integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb08ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Evaluating cluster preservation in predicted embeddings...\")\n",
    "\n",
    "# Create AnnData objects\n",
    "true_adt_adata = ad.AnnData(X=ground_truth)\n",
    "pred_adt_adata = ad.AnnData(X=predictions)\n",
    "\n",
    "# Process both datasets the same way\n",
    "for adata in [true_adt_adata, pred_adt_adata]:\n",
    "    sc.pp.neighbors(adata, n_neighbors=15, use_rep='X')\n",
    "    \n",
    "# Run Leiden clustering with multiple resolutions\n",
    "resolutions = [0.2, 0.5, 0.8, 1.0, 1.5, 2.0]\n",
    "results = []\n",
    "\n",
    "for res in resolutions:\n",
    "    # Cluster true ADT embeddings\n",
    "    sc.tl.leiden(true_adt_adata, resolution=res, key_added=f'leiden_res{res}')\n",
    "    \n",
    "    # Cluster predicted ADT embeddings\n",
    "    sc.tl.leiden(pred_adt_adata, resolution=res, key_added=f'leiden_res{res}')\n",
    "    \n",
    "    # Get cluster labels\n",
    "    true_labels = true_adt_adata.obs[f'leiden_res{res}'].astype(int).values\n",
    "    pred_labels = pred_adt_adata.obs[f'leiden_res{res}'].astype(int).values\n",
    "    \n",
    "    # Calculate metrics\n",
    "    ari = adjusted_rand_score(true_labels, pred_labels)\n",
    "    nmi = normalized_mutual_info_score(true_labels, pred_labels, average_method='arithmetic')\n",
    "    \n",
    "    # Number of clusters\n",
    "    true_n_clusters = len(np.unique(true_labels))\n",
    "    pred_n_clusters = len(np.unique(pred_labels))\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Resolution': res,\n",
    "        'True Clusters': true_n_clusters,\n",
    "        'Predicted Clusters': pred_n_clusters,\n",
    "        'ARI': ari,\n",
    "        'NMI': nmi\n",
    "    })\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Visualize results - make sure to set matplotlib backend explicitly\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(results_df['Resolution'], results_df['ARI'], 'o-', label='ARI')\n",
    "plt.plot(results_df['Resolution'], results_df['NMI'], 'o-', label='NMI')\n",
    "plt.xlabel('Leiden Resolution')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Clustering Agreement Metrics')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(resolutions))\n",
    "plt.bar(x - bar_width/2, results_df['True Clusters'], bar_width, label='True ADT')\n",
    "plt.bar(x + bar_width/2, results_df['Predicted Clusters'], bar_width, label='Predicted ADT')\n",
    "plt.xlabel('Leiden Resolution')\n",
    "plt.ylabel('Number of Clusters')\n",
    "plt.title('Cluster Counts')\n",
    "plt.xticks(x, resolutions)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb70d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use resolution with best ARI score for UMAP visualization\n",
    "best_res_idx = results_df['ARI'].idxmax()\n",
    "best_res = results_df.loc[best_res_idx, 'Resolution']\n",
    "print(f\"\\nBest resolution: {best_res} (ARI: {results_df.loc[best_res_idx, 'ARI']:.4f})\")\n",
    "\n",
    "# UMAP visualization of both embeddings with cluster labels\n",
    "for adata in [true_adt_adata, pred_adt_adata]:\n",
    "    sc.tl.umap(adata)\n",
    "\n",
    "# Create UMAP plots separately using matplotlib rather than scanpy's built-in plotting\n",
    "# This gives us more control over the figure size and ensures the plots aren't truncated\n",
    "\n",
    "# Generate cluster colors for consistency between plots\n",
    "n_clusters = max(\n",
    "    len(np.unique(true_adt_adata.obs[f'leiden_res{best_res}'])),\n",
    "    len(np.unique(pred_adt_adata.obs[f'leiden_res{best_res}']))\n",
    ")\n",
    "cluster_colors = plt.cm.tab20(np.linspace(0, 1, n_clusters))\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# True ADT UMAP\n",
    "plt.subplot(1, 2, 1)\n",
    "true_clusters = true_adt_adata.obs[f'leiden_res{best_res}'].astype(int).values\n",
    "for i in range(n_clusters):\n",
    "    mask = true_clusters == i\n",
    "    if np.any(mask):\n",
    "        plt.scatter(\n",
    "            true_adt_adata.obsm['X_umap'][mask, 0],\n",
    "            true_adt_adata.obsm['X_umap'][mask, 1],\n",
    "            s=10,\n",
    "            color=cluster_colors[i],\n",
    "            label=str(i)\n",
    "        )\n",
    "        \n",
    "        # Add cluster labels\n",
    "        centroid_x = np.mean(true_adt_adata.obsm['X_umap'][mask, 0])\n",
    "        centroid_y = np.mean(true_adt_adata.obsm['X_umap'][mask, 1])\n",
    "        plt.text(centroid_x, centroid_y, str(i), fontweight='bold', fontsize=12, ha='center')\n",
    "\n",
    "plt.title(f'True ADT Embeddings (Resolution: {best_res})')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "# Uncomment the next line if you want a traditional legend\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', ncol=1)\n",
    "\n",
    "# Predicted ADT UMAP\n",
    "plt.subplot(1, 2, 2)\n",
    "pred_clusters = pred_adt_adata.obs[f'leiden_res{best_res}'].astype(int).values\n",
    "for i in range(n_clusters):\n",
    "    mask = pred_clusters == i\n",
    "    if np.any(mask):\n",
    "        plt.scatter(\n",
    "            pred_adt_adata.obsm['X_umap'][mask, 0],\n",
    "            pred_adt_adata.obsm['X_umap'][mask, 1],\n",
    "            s=10,\n",
    "            color=cluster_colors[i],\n",
    "            label=str(i)\n",
    "        )\n",
    "        \n",
    "        # Add cluster labels\n",
    "        centroid_x = np.mean(pred_adt_adata.obsm['X_umap'][mask, 0])\n",
    "        centroid_y = np.mean(pred_adt_adata.obsm['X_umap'][mask, 1])\n",
    "        plt.text(centroid_x, centroid_y, str(i), fontweight='bold', fontsize=12, ha='center')\n",
    "\n",
    "plt.title(f'Predicted ADT Embeddings (Resolution: {best_res})')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "# Uncomment the next line if you want a traditional legend\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', ncol=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('umap_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a52c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Increase the figure size and DPI for better visualization\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "print(\"Evaluating cluster preservation in predicted embeddings...\")\n",
    "\n",
    "# Create AnnData objects\n",
    "true_adt_adata = ad.AnnData(X=ground_truth)\n",
    "pred_adt_adata = ad.AnnData(X=predictions)\n",
    "\n",
    "# Process both datasets the same way\n",
    "for adata in [true_adt_adata, pred_adt_adata]:\n",
    "    sc.pp.neighbors(adata, n_neighbors=15, use_rep='X')\n",
    "    \n",
    "# Run Leiden clustering with multiple resolutions\n",
    "resolutions = [0.2, 0.5, 0.8, 1.0, 1.5, 2.0]\n",
    "results = []\n",
    "\n",
    "for res in resolutions:\n",
    "    # Cluster true ADT embeddings\n",
    "    sc.tl.leiden(true_adt_adata, resolution=res, key_added=f'leiden_res{res}')\n",
    "    \n",
    "    # Cluster predicted ADT embeddings\n",
    "    sc.tl.leiden(pred_adt_adata, resolution=res, key_added=f'leiden_res{res}')\n",
    "    \n",
    "    # Get cluster labels\n",
    "    true_labels = true_adt_adata.obs[f'leiden_res{res}'].astype(int).values\n",
    "    pred_labels = pred_adt_adata.obs[f'leiden_res{res}'].astype(int).values\n",
    "    \n",
    "    # Calculate metrics\n",
    "    ari = adjusted_rand_score(true_labels, pred_labels)\n",
    "    nmi = normalized_mutual_info_score(true_labels, pred_labels, average_method='arithmetic')\n",
    "    \n",
    "    # Number of clusters\n",
    "    true_n_clusters = len(np.unique(true_labels))\n",
    "    pred_n_clusters = len(np.unique(pred_labels))\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Resolution': res,\n",
    "        'True Clusters': true_n_clusters,\n",
    "        'Predicted Clusters': pred_n_clusters,\n",
    "        'ARI': ari,\n",
    "        'NMI': nmi\n",
    "    })\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# Visualize metrics and cluster counts\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(results_df['Resolution'], results_df['ARI'], 'o-', linewidth=2, markersize=8, label='ARI')\n",
    "plt.plot(results_df['Resolution'], results_df['NMI'], 'o-', linewidth=2, markersize=8, label='NMI')\n",
    "plt.xlabel('Leiden Resolution', fontsize=12)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.title('Clustering Agreement Metrics', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xticks(resolutions)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(resolutions))\n",
    "plt.bar(x - bar_width/2, results_df['True Clusters'], bar_width, label='True ADT')\n",
    "plt.bar(x + bar_width/2, results_df['Predicted Clusters'], bar_width, label='Predicted ADT')\n",
    "plt.xlabel('Leiden Resolution', fontsize=12)\n",
    "plt.ylabel('Number of Clusters', fontsize=12)\n",
    "plt.title('Cluster Counts', fontsize=14)\n",
    "plt.xticks(x, resolutions)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cluster_metrics_comparison.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Use resolution with best ARI score for UMAP visualization\n",
    "best_res_idx = results_df['ARI'].idxmax()\n",
    "best_res = results_df.loc[best_res_idx, 'Resolution']\n",
    "print(f\"\\nBest resolution: {best_res} (ARI: {results_df.loc[best_res_idx, 'ARI']:.4f})\")\n",
    "\n",
    "# UMAP visualization of both embeddings with cluster labels\n",
    "for adata in [true_adt_adata, pred_adt_adata]:\n",
    "    # Run UMAP with explicit random state and spread for reproducibility\n",
    "    sc.tl.umap(adata, random_state=42, min_dist=0.3, spread=1.0)\n",
    "\n",
    "# Save the original scanpy plotting parameters\n",
    "original_settings = dict(sc.settings.figdir)\n",
    "\n",
    "# Set scanpy figure parameters to save high-quality figures\n",
    "sc.settings.set_figure_params(dpi=150, dpi_save=300, frameon=True, figsize=(7, 7))\n",
    "\n",
    "# Create a figure for UMAP visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Plot true ADT UMAP\n",
    "sc.pl.umap(true_adt_adata, color=f'leiden_res{best_res}', title=f'True ADT Embeddings (res={best_res})', \n",
    "           show=False, legend_loc='on data', ax=axes[0], legend_fontsize=10)\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].set_xlabel('UMAP1', fontsize=12)\n",
    "axes[0].set_ylabel('UMAP2', fontsize=12)\n",
    "axes[0].grid(False)\n",
    "\n",
    "# Plot predicted ADT UMAP\n",
    "sc.pl.umap(pred_adt_adata, color=f'leiden_res{best_res}', title=f'Predicted ADT Embeddings (res={best_res})', \n",
    "           show=False, legend_loc='on data', ax=axes[1], legend_fontsize=10)\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].set_xlabel('UMAP1', fontsize=12)\n",
    "axes[1].set_ylabel('UMAP2', fontsize=12)\n",
    "axes[1].grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'umap_comparison_res{best_res}.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Restore original scanpy settings\n",
    "sc.settings.figdir = original_settings\n",
    "\n",
    "# Optional: Save the results as CSV for further analysis\n",
    "results_df.to_csv('clustering_metrics.csv', index=False)\n",
    "\n",
    "print(\"Analysis complete. Figures saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Type Performance Metrics: Accuracy, Sensitivity, and Precision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "print(\"Calculating cell type performance metrics...\")\n",
    "\n",
    "# First, ensure we have cluster labels from both RNA and ADT data\n",
    "# We'll use leiden clustering results at the best resolution\n",
    "best_res = results_df.loc[results_df['ARI'].idxmax(), 'Resolution']\n",
    "\n",
    "# Get cluster labels for true and predicted data\n",
    "true_labels = true_adt_adata.obs[f'leiden_res{best_res}'].astype(int).values\n",
    "pred_labels = pred_adt_adata.obs[f'leiden_res{best_res}'].astype(int).values\n",
    "\n",
    "# 1. Build a mapping between predicted and true clusters using maximum overlap\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "cm_norm = cm / cm.sum(axis=1, keepdims=True)  # Normalize by row (true clusters)\n",
    "\n",
    "# For each true cluster, find the predicted cluster with maximum overlap\n",
    "cluster_mapping = {}\n",
    "for i in range(cm.shape[0]):\n",
    "    max_j = np.argmax(cm[i])\n",
    "    cluster_mapping[i] = max_j\n",
    "\n",
    "print(f\"Cluster mapping from true to predicted: {cluster_mapping}\")\n",
    "\n",
    "# 2. Calculate metrics per cell type (cluster)\n",
    "metrics = []\n",
    "unique_clusters = np.unique(true_labels)\n",
    "\n",
    "for cluster in unique_clusters:\n",
    "    # Create binary classification problem for this cluster\n",
    "    true_binary = (true_labels == cluster).astype(int)\n",
    "    pred_binary = (pred_labels == cluster_mapping[cluster]).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_binary, pred_binary)\n",
    "    precision = precision_score(true_binary, pred_binary, zero_division=0)\n",
    "    recall = recall_score(true_binary, pred_binary, zero_division=0)\n",
    "    \n",
    "    # Calculate correlation for cells in this cluster\n",
    "    cluster_mask = (true_labels == cluster)\n",
    "    if np.sum(cluster_mask) > 5:  # Ensure enough samples for correlation\n",
    "        # Get true and predicted embeddings for this cluster\n",
    "        true_emb_cluster = ground_truth[cluster_mask]\n",
    "        pred_emb_cluster = predictions[cluster_mask]\n",
    "        \n",
    "        # Calculate average correlation across dimensions\n",
    "        corr_values = []\n",
    "        for i in range(true_emb_cluster.shape[1]):\n",
    "            r, _ = pearsonr(true_emb_cluster[:, i], pred_emb_cluster[:, i])\n",
    "            corr_values.append(r)\n",
    "        avg_corr = np.mean(corr_values)\n",
    "    else:\n",
    "        avg_corr = np.nan\n",
    "    \n",
    "    # Count cells in this cluster\n",
    "    cell_count = np.sum(cluster_mask)\n",
    "    \n",
    "    metrics.append({\n",
    "        'Cluster': cluster,\n",
    "        'Cell Count': cell_count,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,  # Same as Sensitivity\n",
    "        'Correlation': avg_corr,\n",
    "        'Mapped To': cluster_mapping[cluster]\n",
    "    })\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df = metrics_df.sort_values('Cell Count', ascending=False)\n",
    "\n",
    "# 3. Plot metrics\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Plot metrics side by side with custom colors\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "metrics_subset = metrics_df.sort_values('Cell Count', ascending=False).head(15)  # Top 15 clusters by size\n",
    "\n",
    "bar_width = 0.25\n",
    "x = np.arange(len(metrics_subset))\n",
    "\n",
    "# Plot bars\n",
    "ax1.bar(x - bar_width, metrics_subset['Accuracy'], bar_width, label='Accuracy', color='#3498db')\n",
    "ax1.bar(x, metrics_subset['Precision'], bar_width, label='Precision', color='#2ecc71')\n",
    "ax1.bar(x + bar_width, metrics_subset['Recall'], bar_width, label='Sensitivity', color='#e74c3c')\n",
    "\n",
    "# Add labels and formatting\n",
    "ax1.set_xlabel('Cell Cluster', fontsize=12)\n",
    "ax1.set_ylabel('Score', fontsize=12)\n",
    "ax1.set_title('Accuracy, Precision, and Sensitivity by Cell Cluster', fontsize=14)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([f\"C{c}\\n({n})\" for c, n in zip(metrics_subset['Cluster'], metrics_subset['Cell Count'])])\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# Add value labels above bars\n",
    "for i, metric in enumerate(['Accuracy', 'Precision', 'Recall']):\n",
    "    for j, value in enumerate(metrics_subset[metric]):\n",
    "        ax1.text(j + (i-1)*bar_width, value + 0.02, f\"{value:.2f}\", \n",
    "                ha='center', va='bottom', fontsize=9, rotation=0)\n",
    "\n",
    "# Create a heatmap of all metrics\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "metrics_plot = metrics_df.sort_values('Cell Count', ascending=False).head(20)\n",
    "metrics_heatmap = metrics_plot[['Accuracy', 'Precision', 'Recall', 'Correlation']].copy()\n",
    "metrics_heatmap.index = [f\"C{c} ({n})\" for c, n in zip(metrics_plot['Cluster'], metrics_plot['Cell Count'])]\n",
    "\n",
    "sns.heatmap(metrics_heatmap.T, annot=True, fmt='.2f', cmap='viridis', \n",
    "            linewidths=0.5, ax=ax2, cbar_kws={'label': 'Score'})\n",
    "ax2.set_title('Performance Metrics Heatmap (Top 20 Clusters by Cell Count)', fontsize=14)\n",
    "ax2.set_ylabel('Metric', fontsize=12)\n",
    "ax2.set_xlabel('Cell Cluster (cell count)', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('celltype_performance_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 4. Create scatter plot showing relationship between cluster size and performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Create colormap based on correlation values\n",
    "cmap = plt.cm.viridis\n",
    "norm = plt.Normalize(metrics_df['Correlation'].min(), metrics_df['Correlation'].max())\n",
    "\n",
    "# Plot Accuracy vs Cluster Size\n",
    "axes[0, 0].scatter(metrics_df['Cell Count'], metrics_df['Accuracy'],\n",
    "                   c=metrics_df['Correlation'], cmap=cmap, s=100, alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Cluster Size (Cell Count)', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0, 0].set_title('Accuracy vs Cluster Size', fontsize=14)\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Plot Precision vs Cluster Size\n",
    "axes[0, 1].scatter(metrics_df['Cell Count'], metrics_df['Precision'],\n",
    "                   c=metrics_df['Correlation'], cmap=cmap, s=100, alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Cluster Size (Cell Count)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Precision', fontsize=12)\n",
    "axes[0, 1].set_title('Precision vs Cluster Size', fontsize=14)\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Plot Sensitivity vs Cluster Size\n",
    "axes[1, 0].scatter(metrics_df['Cell Count'], metrics_df['Recall'],\n",
    "                   c=metrics_df['Correlation'], cmap=cmap, s=100, alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Cluster Size (Cell Count)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Sensitivity (Recall)', fontsize=12)\n",
    "axes[1, 0].set_title('Sensitivity vs Cluster Size', fontsize=14)\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Plot Correlation vs Accuracy\n",
    "scatter = axes[1, 1].scatter(metrics_df['Accuracy'], metrics_df['Correlation'],\n",
    "                             c=metrics_df['Cell Count'], cmap='plasma', s=100, alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Accuracy', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Average Correlation', fontsize=12)\n",
    "axes[1, 1].set_title('Correlation vs Accuracy', fontsize=14)\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "# Add a colorbar for correlation in the first 3 plots\n",
    "cbar_ax1 = fig.add_axes([0.92, 0.55, 0.02, 0.3])  # [left, bottom, width, height]\n",
    "cb1 = plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), cax=cbar_ax1)\n",
    "cb1.set_label('Correlation', fontsize=12)\n",
    "\n",
    "# Add a colorbar for cluster size in the last plot\n",
    "cbar_ax2 = fig.add_axes([0.92, 0.15, 0.02, 0.3])  # [left, bottom, width, height]\n",
    "cb2 = plt.colorbar(scatter, cax=cbar_ax2)\n",
    "cb2.set_label('Cluster Size', fontsize=12)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1])  # Adjust layout to make room for colorbars\n",
    "plt.savefig('celltype_metrics_scatter.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 5. Summary statistics\n",
    "print(\"\\nSummary Statistics for Cell Type Performance:\")\n",
    "print(f\"Overall Mean Accuracy: {metrics_df['Accuracy'].mean():.4f}\")\n",
    "print(f\"Overall Mean Precision: {metrics_df['Precision'].mean():.4f}\")\n",
    "print(f\"Overall Mean Sensitivity: {metrics_df['Recall'].mean():.4f}\")\n",
    "print(f\"Overall Mean Correlation: {metrics_df['Correlation'].mean():.4f}\")\n",
    "\n",
    "# Best and worst performing clusters\n",
    "best_cluster = metrics_df.loc[metrics_df['Accuracy'].idxmax()]\n",
    "worst_cluster = metrics_df.loc[metrics_df['Accuracy'].idxmin()]\n",
    "\n",
    "print(f\"\\nBest performing cluster: Cluster {best_cluster['Cluster']} with {best_cluster['Cell Count']} cells\")\n",
    "print(f\"  Accuracy: {best_cluster['Accuracy']:.4f}, Precision: {best_cluster['Precision']:.4f}, Sensitivity: {best_cluster['Recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nWorst performing cluster: Cluster {worst_cluster['Cluster']} with {worst_cluster['Cell Count']} cells\")\n",
    "print(f\"  Accuracy: {worst_cluster['Accuracy']:.4f}, Precision: {worst_cluster['Precision']:.4f}, Sensitivity: {worst_cluster['Recall']:.4f}\")\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df.to_csv('celltype_performance_metrics.csv', index=False)\n",
    "print(\"\\nMetrics saved to 'celltype_performance_metrics.csv'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
