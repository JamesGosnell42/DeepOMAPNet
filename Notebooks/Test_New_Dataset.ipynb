{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing Trained Models on New Single Cell Dataset\n",
        "\n",
        "This notebook demonstrates how to load new single cell data and test it using the trained RNA-to-ADT transformer mapping models.\n",
        "\n",
        "## Overview\n",
        "1. Load new single cell RNA data\n",
        "2. Load pre-trained models\n",
        "3. Preprocess new data\n",
        "4. Extract embeddings and make predictions\n",
        "5. Evaluate performance (if ground truth available)\n",
        "6. Visualize results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os, importlib\n",
        "\n",
        "# --- Autoreload ---\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# --- Paths ---\n",
        "current_dir = os.getcwd()\n",
        "if 'Notebooks' in current_dir:\n",
        "    parent_dir = os.path.dirname(current_dir)\n",
        "    scripts_path = os.path.join(parent_dir, 'scripts')\n",
        "else:\n",
        "    parent_dir = current_dir\n",
        "    scripts_path = os.path.join(current_dir, 'scripts')\n",
        "\n",
        "if parent_dir not in sys.path:\n",
        "    sys.path.append(parent_dir)\n",
        "if scripts_path not in sys.path:\n",
        "    sys.path.append(scripts_path)\n",
        "\n",
        "print(\"Added to Python path:\")\n",
        "print(f\"- Parent directory: {parent_dir}\")\n",
        "print(f\"- Scripts directory: {scripts_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import anndata as ad\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# Import custom modules\n",
        "import scripts.Embeddings_extract as Embeddings_extract\n",
        "import scripts.GATmodel as GATmodel\n",
        "import scripts.TransformerMap as TransformerMap\n",
        "\n",
        "print(\"All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load New Single Cell Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load your new single cell dataset\n",
        "# Replace with your actual data path\n",
        "new_rna_path = \"path/to/your/new_rna_data.h5ad\"\n",
        "new_adt_path = \"path/to/your/new_adt_data.h5ad\"  # Optional, for validation\n",
        "\n",
        "# Example: Load data (uncomment and modify paths as needed)\n",
        "# new_rna_data = sc.read_h5ad(new_rna_path)\n",
        "# new_adt_data = sc.read_h5ad(new_adt_path) if new_adt_path else None\n",
        "\n",
        "# Option 1: Load GSE116256 dataset (AML samples)\n",
        "# Uncomment the following lines to load the real GSE116256 dataset\n",
        "\"\"\"\n",
        "import sys\n",
        "sys.path.append('..')  # Add parent directory to path\n",
        "from load_gse116256 import load_gse116256_dataset\n",
        "\n",
        "print(\"Loading GSE116256 dataset...\")\n",
        "new_rna_data = load_gse116256_dataset(\n",
        "    data_dir=\"/projects/vanaja_lab/satya/Datasets/GSE116256\",\n",
        "    output_file=\"GSE116256_combined.h5ad\",\n",
        "    force_reload=False  # Set to True to reload from raw files\n",
        ")\n",
        "new_adt_data = None  # No ADT data available for this dataset\n",
        "print(f\"GSE116256 dataset loaded: {new_rna_data.shape}\")\n",
        "print(f\"Sample IDs: {new_rna_data.obs['sample_id'].unique()[:10]}\")\n",
        "\"\"\"\n",
        "\n",
        "# Option 2: For demonstration, create sample data\n",
        "print(\"Creating sample data for demonstration...\")\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create sample RNA data\n",
        "n_cells = 5000\n",
        "n_genes = 2000\n",
        "sample_rna_data = np.random.negative_binomial(5, 0.3, (n_cells, n_genes))\n",
        "\n",
        "# Create AnnData object\n",
        "new_rna_data = ad.AnnData(X=sample_rna_data)\n",
        "new_rna_data.var_names = [f\"Gene_{i}\" for i in range(n_genes)]\n",
        "new_rna_data.obs_names = [f\"Cell_{i}\" for i in range(n_cells)]\n",
        "\n",
        "# Add some metadata\n",
        "new_rna_data.obs['sample_id'] = np.random.choice(['Sample_A', 'Sample_B', 'Sample_C'], n_cells)\n",
        "new_rna_data.obs['cell_type'] = np.random.choice(['T_cell', 'B_cell', 'Monocyte', 'NK_cell'], n_cells)\n",
        "\n",
        "print(f\"Sample RNA data shape: {new_rna_data.shape}\")\n",
        "print(f\"Sample metadata: {new_rna_data.obs.columns.tolist()}\")\n",
        "\n",
        "# If you have real data, uncomment the appropriate option above\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Pre-trained Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the path to your trained models\n",
        "# Update this path to match your saved model checkpoint\n",
        "models_dir = \"trained_models\"\n",
        "\n",
        "# Find the most recent checkpoint\n",
        "checkpoint_files = [f for f in os.listdir(models_dir) if f.startswith('rna_adt_transformer_models_') and f.endswith('.pth')]\n",
        "if checkpoint_files:\n",
        "    # Sort by timestamp and get the most recent\n",
        "    checkpoint_files.sort(reverse=True)\n",
        "    latest_checkpoint = checkpoint_files[0]\n",
        "    checkpoint_path = os.path.join(models_dir, latest_checkpoint)\n",
        "    print(f\"Loading checkpoint: {latest_checkpoint}\")\n",
        "else:\n",
        "    print(\"No checkpoint files found. Please train models first.\")\n",
        "    checkpoint_path = None\n",
        "\n",
        "# Load the checkpoint\n",
        "if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "    print(\"‚úÖ Checkpoint loaded successfully\")\n",
        "    \n",
        "    # Display checkpoint information\n",
        "    print(f\"\\nüìä Model Information:\")\n",
        "    print(f\"   ‚Ä¢ RNA input dimension: {checkpoint['rna_input_dim']}\")\n",
        "    print(f\"   ‚Ä¢ ADT output dimension: {checkpoint['adt_output_dim']}\")\n",
        "    print(f\"   ‚Ä¢ RNA classes: {checkpoint['rna_num_classes']}\")\n",
        "    print(f\"   ‚Ä¢ ADT classes: {checkpoint['adt_num_classes']}\")\n",
        "    print(f\"   ‚Ä¢ Training timestamp: {checkpoint['training_config']['timestamp']}\")\n",
        "    \n",
        "    # Display performance metrics\n",
        "    perf = checkpoint['performance_metrics']\n",
        "    print(f\"\\nüéØ Training Performance:\")\n",
        "    print(f\"   ‚Ä¢ Final test loss: {perf['final_test_loss']:.4f}\")\n",
        "    print(f\"   ‚Ä¢ MSE: {perf['mse']:.4f}\")\n",
        "    print(f\"   ‚Ä¢ R¬≤ Score: {perf['r2']:.4f}\")\n",
        "    print(f\"   ‚Ä¢ Mean Pearson correlation: {perf['mean_pearson']:.4f}\")\n",
        "    print(f\"   ‚Ä¢ Mean Spearman correlation: {perf['mean_spearman']:.4f}\")\n",
        "else:\n",
        "    print(\"‚ùå No valid checkpoint found. Please train models first.\")\n",
        "    checkpoint = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize models with the loaded configuration\n",
        "if checkpoint is not None:\n",
        "    from scripts.GATmodel import SimpleGAT\n",
        "    from scripts.TransformerMap import TransformerMapping\n",
        "    \n",
        "    # Initialize RNA GAT model\n",
        "    rna_gat_model = SimpleGAT(\n",
        "        in_channels=checkpoint['rna_input_dim'],\n",
        "        hidden_channels=64,\n",
        "        out_channels=35,  # Fixed based on training\n",
        "        heads=4,\n",
        "        dropout=0.6\n",
        "    )\n",
        "    \n",
        "    # Initialize ADT GAT model\n",
        "    adt_gat_model = SimpleGAT(\n",
        "        in_channels=50,\n",
        "        hidden_channels=64,\n",
        "        out_channels=51,  # Fixed based on training\n",
        "        heads=4,\n",
        "        dropout=0.6\n",
        "    )\n",
        "    \n",
        "    # Initialize Transformer mapping model\n",
        "    transformer_model = TransformerMapping(\n",
        "        input_dim=checkpoint['rna_input_dim'],\n",
        "        output_dim=checkpoint['adt_output_dim'],\n",
        "        d_model=256,\n",
        "        nhead=4,\n",
        "        num_layers=3\n",
        "    )\n",
        "    \n",
        "    # Load weights\n",
        "    rna_gat_model.load_state_dict(checkpoint['rna_gat_state_dict'])\n",
        "    adt_gat_model.load_state_dict(checkpoint['adt_gat_state_dict'])\n",
        "    transformer_model.load_state_dict(checkpoint['transformer_mapping_state_dict'])\n",
        "    \n",
        "    # Set to evaluation mode\n",
        "    rna_gat_model.eval()\n",
        "    adt_gat_model.eval()\n",
        "    transformer_model.eval()\n",
        "    \n",
        "    print(\"‚úÖ All models loaded and set to evaluation mode\")\n",
        "else:\n",
        "    print(\"‚ùå Cannot initialize models without checkpoint\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Preprocess New Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess new RNA data to match training data format\n",
        "def preprocess_new_rna_data(adata):\n",
        "    \"\"\"\n",
        "    Preprocess new RNA data to match the training data format\n",
        "    \"\"\"\n",
        "    print(f\"Original data shape: {adata.shape}\")\n",
        "    \n",
        "    # Store raw data\n",
        "    adata.layers[\"raw\"] = adata.X.copy()\n",
        "    \n",
        "    # Basic preprocessing\n",
        "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
        "    sc.pp.log1p(adata)\n",
        "    \n",
        "    # Select highly variable genes\n",
        "    sc.pp.highly_variable_genes(adata, n_top_genes=2000)\n",
        "    adata = adata[:, adata.var.highly_variable].copy()\n",
        "    \n",
        "    # Scale data\n",
        "    sc.pp.scale(adata, max_value=10)\n",
        "    \n",
        "    # Compute PCA\n",
        "    sc.tl.pca(adata, n_comps=50, svd_solver=\"arpack\")\n",
        "    \n",
        "    print(f\"Preprocessed data shape: {adata.shape}\")\n",
        "    print(f\"PCA components: {adata.obsm['X_pca'].shape}\")\n",
        "    \n",
        "    return adata\n",
        "\n",
        "# Preprocess the new data\n",
        "if checkpoint is not None:\n",
        "    processed_rna_data = preprocess_new_rna_data(new_rna_data.copy())\n",
        "    print(\"‚úÖ New RNA data preprocessed successfully\")\n",
        "else:\n",
        "    print(\"‚ùå Cannot preprocess data without loaded models\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Extract Embeddings and Make Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build PyTorch Geometric data object and extract embeddings\n",
        "def predict_adt_embeddings(rna_data, rna_gat_model, transformer_model):\n",
        "    \"\"\"\n",
        "    Extract RNA embeddings and predict ADT embeddings\n",
        "    \"\"\"\n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "    \n",
        "    # Move models to device\n",
        "    rna_gat_model.to(device)\n",
        "    transformer_model.to(device)\n",
        "    \n",
        "    # Build PyG data object\n",
        "    print(\"Building PyTorch Geometric data object...\")\n",
        "    rna_pyg_data, _, config = Embeddings_extract.process_data_with_graphs(\n",
        "        rna_data, \n",
        "        None,  # No ADT data for new dataset\n",
        "        n_neighbors=20,\n",
        "        rna_sparse_threshold=10000000,\n",
        "        rna_max_edges_sparse=75\n",
        "    )\n",
        "    \n",
        "    print(f\"PyG data - Nodes: {rna_pyg_data.num_nodes}, Edges: {rna_pyg_data.num_edges}\")\n",
        "    \n",
        "    # Move data to device\n",
        "    rna_pyg_data = rna_pyg_data.to(device)\n",
        "    \n",
        "    # Extract RNA embeddings\n",
        "    print(\"Extracting RNA embeddings...\")\n",
        "    with torch.no_grad():\n",
        "        rna_embeddings = Embeddings_extract.extract_embeddings(rna_gat_model, rna_pyg_data)\n",
        "    \n",
        "    # Predict ADT embeddings\n",
        "    print(\"Predicting ADT embeddings...\")\n",
        "    with torch.no_grad():\n",
        "        predicted_adt_embeddings = transformer_model(rna_embeddings)\n",
        "    \n",
        "    # Move to CPU for further processing\n",
        "    rna_embeddings = rna_embeddings.cpu()\n",
        "    predicted_adt_embeddings = predicted_adt_embeddings.cpu()\n",
        "    \n",
        "    print(f\"RNA embeddings shape: {rna_embeddings.shape}\")\n",
        "    print(f\"Predicted ADT embeddings shape: {predicted_adt_embeddings.shape}\")\n",
        "    \n",
        "    return rna_embeddings, predicted_adt_embeddings, rna_pyg_data\n",
        "\n",
        "# Make predictions\n",
        "if checkpoint is not None:\n",
        "    rna_embeddings, predicted_adt_embeddings, rna_pyg_data = predict_adt_embeddings(\n",
        "        processed_rna_data, rna_gat_model, transformer_model\n",
        "    )\n",
        "    print(\"‚úÖ Predictions completed successfully\")\n",
        "else:\n",
        "    print(\"‚ùå Cannot make predictions without loaded models\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluate Performance (if ground truth available)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate performance if ground truth ADT data is available\n",
        "def evaluate_predictions(predicted_embeddings, true_embeddings=None, true_adt_data=None):\n",
        "    \"\"\"\n",
        "    Evaluate prediction performance\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    if true_adt_data is not None:\n",
        "        print(\"Ground truth ADT data available - computing performance metrics...\")\n",
        "        \n",
        "        # Preprocess true ADT data\n",
        "        processed_adt_data = preprocess_new_rna_data(true_adt_data.copy())  # Reuse RNA preprocessing\n",
        "        \n",
        "        # Extract true ADT embeddings\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        adt_gat_model.to(device)\n",
        "        \n",
        "        adt_pyg_data, _, _ = Embeddings_extract.process_data_with_graphs(\n",
        "            None, processed_adt_data,\n",
        "            n_neighbors=20,\n",
        "            adt_max_edges_sparse=75\n",
        "        )\n",
        "        \n",
        "        adt_pyg_data = adt_pyg_data.to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            true_adt_embeddings = Embeddings_extract.extract_embeddings(adt_gat_model, adt_pyg_data)\n",
        "        \n",
        "        true_adt_embeddings = true_adt_embeddings.cpu()\n",
        "        \n",
        "        # Calculate metrics\n",
        "        mse = mean_squared_error(true_adt_embeddings, predicted_embeddings)\n",
        "        r2 = r2_score(true_adt_embeddings, predicted_embeddings)\n",
        "        \n",
        "        # Calculate correlation per dimension\n",
        "        correlations = []\n",
        "        for i in range(true_adt_embeddings.shape[1]):\n",
        "            r, _ = pearsonr(true_adt_embeddings[:, i], predicted_embeddings[:, i])\n",
        "            correlations.append(r)\n",
        "        \n",
        "        mean_correlation = np.mean(correlations)\n",
        "        median_correlation = np.median(correlations)\n",
        "        \n",
        "        results = {\n",
        "            'mse': mse,\n",
        "            'r2': r2,\n",
        "            'mean_correlation': mean_correlation,\n",
        "            'median_correlation': median_correlation,\n",
        "            'correlations': correlations\n",
        "        }\n",
        "        \n",
        "        print(f\"\\nüìä Performance Metrics:\")\n",
        "        print(f\"   ‚Ä¢ MSE: {mse:.4f}\")\n",
        "        print(f\"   ‚Ä¢ R¬≤ Score: {r2:.4f}\")\n",
        "        print(f\"   ‚Ä¢ Mean Correlation: {mean_correlation:.4f}\")\n",
        "        print(f\"   ‚Ä¢ Median Correlation: {median_correlation:.4f}\")\n",
        "        \n",
        "    else:\n",
        "        print(\"No ground truth ADT data available - skipping performance evaluation\")\n",
        "        results = {'status': 'no_ground_truth'}\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Evaluate predictions (uncomment if you have ground truth data)\n",
        "# evaluation_results = evaluate_predictions(predicted_adt_embeddings, true_adt_data=new_adt_data)\n",
        "evaluation_results = evaluate_predictions(predicted_adt_embeddings, true_adt_data=None)\n",
        "print(\"‚úÖ Evaluation completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualize Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizations of the predicted embeddings\n",
        "def visualize_predictions(predicted_embeddings, rna_data, metadata_columns=None):\n",
        "    \"\"\"\n",
        "    Create visualizations of predicted ADT embeddings\n",
        "    \"\"\"\n",
        "    # Create AnnData object for predicted embeddings\n",
        "    pred_adata = ad.AnnData(X=predicted_embeddings.numpy())\n",
        "    pred_adata.obs = rna_data.obs.copy()\n",
        "    \n",
        "    # Compute neighbors and UMAP\n",
        "    sc.pp.neighbors(pred_adata, n_neighbors=15, use_rep='X')\n",
        "    sc.tl.umap(pred_adata)\n",
        "    \n",
        "    # Create plots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    \n",
        "    # UMAP colored by sample\n",
        "    if 'sample_id' in pred_adata.obs:\n",
        "        sc.pl.umap(pred_adata, color='sample_id', ax=axes[0,0], show=False, title='Predicted ADT Embeddings - Sample')\n",
        "    \n",
        "    # UMAP colored by cell type\n",
        "    if 'cell_type' in pred_adata.obs:\n",
        "        sc.pl.umap(pred_adata, color='cell_type', ax=axes[0,1], show=False, title='Predicted ADT Embeddings - Cell Type')\n",
        "    \n",
        "    # Distribution of embedding values\n",
        "    axes[1,0].hist(predicted_embeddings.numpy().flatten(), bins=50, alpha=0.7)\n",
        "    axes[1,0].set_title('Distribution of Predicted Embedding Values')\n",
        "    axes[1,0].set_xlabel('Embedding Value')\n",
        "    axes[1,0].set_ylabel('Frequency')\n",
        "    \n",
        "    # Embedding dimension correlation heatmap (first 20 dimensions)\n",
        "    n_dims = min(20, predicted_embeddings.shape[1])\n",
        "    corr_matrix = np.corrcoef(predicted_embeddings[:, :n_dims].T)\n",
        "    im = axes[1,1].imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "    axes[1,1].set_title(f'Correlation Matrix (First {n_dims} Dimensions)')\n",
        "    axes[1,1].set_xlabel('Embedding Dimension')\n",
        "    axes[1,1].set_ylabel('Embedding Dimension')\n",
        "    plt.colorbar(im, ax=axes[1,1])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return pred_adata\n",
        "\n",
        "# Create visualizations\n",
        "if checkpoint is not None:\n",
        "    pred_adata = visualize_predictions(predicted_adt_embeddings, processed_rna_data)\n",
        "    print(\"‚úÖ Visualizations created successfully\")\n",
        "else:\n",
        "    print(\"‚ùå Cannot create visualizations without predictions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results for further analysis\n",
        "def save_test_results(predicted_embeddings, rna_data, evaluation_results=None, output_dir=\"test_results\"):\n",
        "    \"\"\"\n",
        "    Save test results and predictions\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    # Save predicted embeddings\n",
        "    pred_adata = ad.AnnData(X=predicted_embeddings.numpy())\n",
        "    pred_adata.obs = rna_data.obs.copy()\n",
        "    pred_adata.var_names = [f\"ADT_Dim_{i}\" for i in range(predicted_embeddings.shape[1])]\n",
        "    \n",
        "    pred_path = os.path.join(output_dir, f\"predicted_adt_embeddings_{timestamp}.h5ad\")\n",
        "    pred_adata.write(pred_path)\n",
        "    \n",
        "    # Save results summary\n",
        "    results_summary = {\n",
        "        'test_info': {\n",
        "            'timestamp': timestamp,\n",
        "            'n_cells': predicted_embeddings.shape[0],\n",
        "            'n_embedding_dims': predicted_embeddings.shape[1],\n",
        "            'model_checkpoint': checkpoint_path if checkpoint_path else 'None'\n",
        "        },\n",
        "        'evaluation_results': evaluation_results if evaluation_results else {'status': 'no_evaluation'},\n",
        "        'file_paths': {\n",
        "            'predicted_embeddings': pred_path\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    summary_path = os.path.join(output_dir, f\"test_summary_{timestamp}.json\")\n",
        "    with open(summary_path, 'w') as f:\n",
        "        json.dump(results_summary, f, indent=2)\n",
        "    \n",
        "    print(f\"‚úÖ Results saved to: {output_dir}\")\n",
        "    print(f\"   üìÑ Predicted embeddings: {pred_path}\")\n",
        "    print(f\"   üìä Test summary: {summary_path}\")\n",
        "    \n",
        "    return pred_path, summary_path\n",
        "\n",
        "# Save results\n",
        "if checkpoint is not None:\n",
        "    pred_path, summary_path = save_test_results(\n",
        "        predicted_adt_embeddings, \n",
        "        processed_rna_data, \n",
        "        evaluation_results\n",
        "    )\n",
        "    print(\"‚úÖ All results saved successfully\")\n",
        "else:\n",
        "    print(\"‚ùå Cannot save results without predictions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary and Next Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display final summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéØ TESTING COMPLETE - SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if checkpoint is not None:\n",
        "    print(f\"\\nüìä Dataset Information:\")\n",
        "    print(f\"   ‚Ä¢ Total cells tested: {predicted_adt_embeddings.shape[0]:,}\")\n",
        "    print(f\"   ‚Ä¢ Embedding dimensions: {predicted_adt_embeddings.shape[1]}\")\n",
        "    print(f\"   ‚Ä¢ Model checkpoint: {os.path.basename(checkpoint_path)}\")\n",
        "    \n",
        "    if evaluation_results and 'status' not in evaluation_results:\n",
        "        print(f\"\\nüéØ Performance Metrics:\")\n",
        "        print(f\"   ‚Ä¢ MSE: {evaluation_results['mse']:.4f}\")\n",
        "        print(f\"   ‚Ä¢ R¬≤ Score: {evaluation_results['r2']:.4f}\")\n",
        "        print(f\"   ‚Ä¢ Mean Correlation: {evaluation_results['mean_correlation']:.4f}\")\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è  No ground truth available for performance evaluation\")\n",
        "    \n",
        "    print(f\"\\nüìÅ Output Files:\")\n",
        "    print(f\"   ‚Ä¢ Predicted embeddings: {pred_path}\")\n",
        "    print(f\"   ‚Ä¢ Test summary: {summary_path}\")\n",
        "    \n",
        "    print(f\"\\nüöÄ Next Steps:\")\n",
        "    print(f\"   1. Load predicted embeddings for downstream analysis\")\n",
        "    print(f\"   2. Perform cell type annotation using predicted embeddings\")\n",
        "    print(f\"   3. Compare with known cell type markers\")\n",
        "    print(f\"   4. Use for cross-modal integration studies\")\n",
        "    \n",
        "else:\n",
        "    print(\"\\n‚ùå Testing failed - no valid models loaded\")\n",
        "    print(\"   Please ensure you have trained models saved in the 'trained_models' directory\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Example Usage for Future Testing\n",
        "\n",
        "To test new datasets in the future, you can use this simplified function:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simplified function for testing new datasets\n",
        "def test_new_dataset(rna_data_path, adt_data_path=None, models_dir=\"trained_models\"):\n",
        "    \"\"\"\n",
        "    Simplified function to test new single cell dataset\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    rna_data_path : str\n",
        "        Path to new RNA data (.h5ad file)\n",
        "    adt_data_path : str, optional\n",
        "        Path to ground truth ADT data for validation\n",
        "    models_dir : str\n",
        "        Directory containing trained models\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Results dictionary with predictions and metrics\n",
        "    \"\"\"\n",
        "    \n",
        "    # Load data\n",
        "    rna_data = sc.read_h5ad(rna_data_path)\n",
        "    adt_data = sc.read_h5ad(adt_data_path) if adt_data_path else None\n",
        "    \n",
        "    # Find latest checkpoint\n",
        "    checkpoint_files = [f for f in os.listdir(models_dir) if f.startswith('rna_adt_transformer_models_')]\n",
        "    if not checkpoint_files:\n",
        "        raise FileNotFoundError(\"No trained models found\")\n",
        "    \n",
        "    checkpoint_files.sort(reverse=True)\n",
        "    checkpoint_path = os.path.join(models_dir, checkpoint_files[0])\n",
        "    \n",
        "    # Load models\n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "    \n",
        "    # Initialize and load models (same as above)\n",
        "    # ... (model initialization code)\n",
        "    \n",
        "    # Preprocess and predict\n",
        "    processed_rna = preprocess_new_rna_data(rna_data)\n",
        "    rna_emb, pred_adt_emb, _ = predict_adt_embeddings(processed_rna, rna_gat_model, transformer_model)\n",
        "    \n",
        "    # Evaluate if ground truth available\n",
        "    eval_results = evaluate_predictions(pred_adt_emb, true_adt_data=adt_data)\n",
        "    \n",
        "    # Save results\n",
        "    pred_path, summary_path = save_test_results(pred_adt_emb, processed_rna, eval_results)\n",
        "    \n",
        "    return {\n",
        "        'predictions': pred_adt_emb,\n",
        "        'evaluation': eval_results,\n",
        "        'files': {'predictions': pred_path, 'summary': summary_path}\n",
        "    }\n",
        "\n",
        "# Example usage:\n",
        "# results = test_new_dataset('path/to/new_rna.h5ad', 'path/to/new_adt.h5ad')\n",
        "print(\"‚úÖ Simplified testing function defined\")\n",
        "print(\"   Use: results = test_new_dataset('path/to/rna_data.h5ad', 'path/to/adt_data.h5ad')\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
